{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import dotenv\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "from config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE APP VERSION TO TEST\n",
    "\n",
    "version = \"ct-fema-ocfo-gpt-llamaIndexTest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET ALL CONFIGURATIONS AUTOMATICALLY \n",
    "\n",
    "env_file = dotenv.find_dotenv()\n",
    "dotenv.load_dotenv(env_file)\n",
    "dotenv.set_key(env_file, \"VERSION_ID\", version)\n",
    "\n",
    "settings.VERSION_ID = version\n",
    "settings.get_version_configs()\n",
    "\n",
    "# Overwrite system settings with experiment-specific configs\n",
    "settings.SHOULD_STREAM = False\n",
    "settings.AZURE_OPENAI_MODEL = \"dep-gpt-35-16k\"\n",
    "settings.AZURE_OPENAI_MODEL_NAME = \"gpt-35-turbo-16k\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = settings.AZURE_OPENAI_KEY\n",
    "\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(settings.PREP_CONFIG, f)\n",
    "\n",
    "RETRIES = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3: Try Adding Node Relationships and Summary / Title Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data utilities for index preparation.\"\"\"\n",
    "import ast\n",
    "from asyncio import sleep\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from openai import AzureOpenAI\n",
    "from abc import ABC, abstractmethod\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Optional, Generator, Tuple\n",
    "\n",
    "import tiktoken\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from langchain.text_splitter import MarkdownTextSplitter, RecursiveCharacterTextSplitter, PythonCodeTextSplitter\n",
    "from llama_index.node_parser import LangchainNodeParser\n",
    "from llama_index import download_loader\n",
    "from llama_index import Document as LlamaDocument\n",
    "from llama_index.extractors import TitleExtractor, SummaryExtractor, QuestionsAnsweredExtractor\n",
    "from llama_index.ingestion import IngestionPipeline\n",
    "from llama_index.llms import AzureOpenAI as LlamaAOAI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "FILE_FORMAT_DICT = {\n",
    "        \"md\": \"markdown\",\n",
    "        \"txt\": \"text\",\n",
    "        \"html\": \"html\",\n",
    "        \"shtml\": \"html\",\n",
    "        \"htm\": \"html\",\n",
    "        \"py\": \"python\",\n",
    "        \"pdf\": \"pdf\",\n",
    "        \"json\": \"json\"\n",
    "    }\n",
    "\n",
    "RETRY_COUNT = 5\n",
    "\n",
    "SENTENCE_ENDINGS = [\".\", \"!\", \"?\"]\n",
    "WORDS_BREAKS = list(reversed([\",\", \";\", \":\", \" \", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"\\t\", \"\\n\"]))\n",
    "PDFReader = download_loader(\"PDFReader\")\n",
    "\n",
    "@dataclass\n",
    "class Document(object):\n",
    "    \"\"\"A data class for storing documents\n",
    "\n",
    "    Attributes:\n",
    "        content (str): The content of the document.\n",
    "        id (Optional[str]): The id of the document.\n",
    "        title (Optional[str]): The title of the document.\n",
    "        filepath (Optional[str]): The filepath of the document.\n",
    "        url (Optional[str]): The url of the document.\n",
    "        metadata (Optional[Dict]): The metadata of the document.    \n",
    "    \"\"\"\n",
    "\n",
    "    content: str\n",
    "    id: Optional[str] = None\n",
    "    title: Optional[str] = None\n",
    "    filepath: Optional[str] = None\n",
    "    url: Optional[str] = None\n",
    "    metadata: Optional[Dict] = None\n",
    "    contentVector: Optional[List[float]] = None\n",
    "\n",
    "def cleanup_content(content: str) -> str:\n",
    "    \"\"\"Cleans up the given content using regexes\n",
    "    Args:\n",
    "        content (str): The content to clean up.\n",
    "    Returns:\n",
    "        str: The cleaned up content.\n",
    "    \"\"\"\n",
    "    output = re.sub(r\"\\n{2,}\", \"\\n\", content)\n",
    "    output = re.sub(r\"[^\\S\\n]{2,}\", \" \", output)\n",
    "    output = re.sub(r\"-{2,}\", \"--\", output)\n",
    "\n",
    "    return output.strip()\n",
    "\n",
    "class BaseParser(ABC):\n",
    "    \"\"\"A parser parses content to produce a document.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def parse(self, content: str, file_name: Optional[str] = None) -> Document:\n",
    "        \"\"\"Parses the given content.\n",
    "        Args:\n",
    "            content (str): The content to parse.\n",
    "            file_name (str): The file name associated with the content.\n",
    "        Returns:\n",
    "            Document: The parsed document.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def parse_file(self, file_path: str) -> Document:\n",
    "        \"\"\"Parses the given file.\n",
    "        Args:\n",
    "            file_path (str): The file to parse.\n",
    "        Returns:\n",
    "            Document: The parsed document.\n",
    "        \"\"\"\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return self.parse(f.read(), os.path.basename(file_path))\n",
    "\n",
    "    def parse_directory(self, directory_path: str) -> List[Document]:\n",
    "        \"\"\"Parses the given directory.\n",
    "        Args:\n",
    "            directory_path (str): The directory to parse.\n",
    "        Returns:\n",
    "            List[Document]: List of parsed documents.\n",
    "        \"\"\"\n",
    "        documents = []\n",
    "        for file_name in os.listdir(directory_path):\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            if os.path.isfile(file_path):\n",
    "                documents.append(self.parse_file(file_path))\n",
    "        return documents\n",
    "\n",
    "class TextParser(BaseParser):\n",
    "    \"\"\"Parses text content.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def _get_first_alphanum_line(self, content: str) -> Optional[str]:\n",
    "        title = None\n",
    "        for line in content.splitlines():\n",
    "            if any([c.isalnum() for c in line]):\n",
    "                title = line.strip()\n",
    "                break\n",
    "        return title\n",
    "\n",
    "    def _get_first_line_with_property(\n",
    "        self, content: str, property: str = \"title: \"\n",
    "    ) -> Optional[str]:\n",
    "        title = None\n",
    "        for line in content.splitlines():\n",
    "            if line.startswith(property):\n",
    "                title = line[len(property) :].strip()\n",
    "                break\n",
    "        return title\n",
    "\n",
    "    def parse(self, content: str, file_name: Optional[str] = None) -> Document:\n",
    "        \"\"\"Parses the given content.\n",
    "        Args:\n",
    "            content (str): The content to parse.\n",
    "            file_name (str): The file name associated with the content.\n",
    "        Returns:\n",
    "            Document: The parsed document.\n",
    "        \"\"\"\n",
    "        title = self._get_first_line_with_property(\n",
    "            content\n",
    "        ) or self._get_first_alphanum_line(content)\n",
    "\n",
    "        return Document(content=cleanup_content(content), title=title or file_name)\n",
    "\n",
    "class UnsupportedFormatError(Exception):\n",
    "    \"\"\"Exception raised when a format is not supported by a parser.\"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "class ParserFactory:\n",
    "    def __init__(self):\n",
    "        self._parsers = {\n",
    "            \"text\": TextParser(),\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def supported_formats(self) -> List[str]:\n",
    "        \"Returns a list of supported formats\"\n",
    "        return list(self._parsers.keys())\n",
    "\n",
    "    def __call__(self, file_format: str) -> BaseParser:\n",
    "        parser = self._parsers.get(file_format, None)\n",
    "        if parser is None:\n",
    "            raise UnsupportedFormatError(f\"{file_format} is not supported\")\n",
    "\n",
    "        return parser\n",
    "    \n",
    "\n",
    "class LlamaIndexSplitter:\n",
    "    def __init__(self, num_tokens, token_overlap, extractor_llm=None):\n",
    "        splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            separators=SENTENCE_ENDINGS + WORDS_BREAKS,\n",
    "            chunk_size=num_tokens, chunk_overlap=token_overlap)\n",
    "        parser = LangchainNodeParser(splitter)\n",
    "        self.parser = parser\n",
    "        self.extractor_llm = extractor_llm\n",
    "        self.split_mods_map = {\n",
    "            \"summary_extraction\": SummaryExtractor(summaries=[\"prev\", \"self\", \"next\"], llm=extractor_llm),\n",
    "            \"qa_extraction\": QuestionsAnsweredExtractor(questions=3, llm=extractor_llm)\n",
    "        }\n",
    "    \n",
    "    def get_nodes_from_doc(self, llama_doc, split_mods):\n",
    "        if split_mods and self.extractor_llm == None:\n",
    "            raise ValueError(f\"extractor_llm argument is required to apply modifications during splitting\")\n",
    "\n",
    "        pipeline = IngestionPipeline(\n",
    "            transformations=[self.parser] + [self.split_mods_map[mod] for mod in split_mods]\n",
    "        )\n",
    "\n",
    "        nodes = pipeline.run(\n",
    "            documents = [llama_doc],\n",
    "            in_place=True,\n",
    "            show_progress=True\n",
    "        )\n",
    "\n",
    "        return nodes\n",
    "    \n",
    "\n",
    "class TokenEstimator(object):\n",
    "    GPT2_TOKENIZER = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    def estimate_tokens(self, text: str) -> int:\n",
    "        return len(self.GPT2_TOKENIZER.encode(text))\n",
    "\n",
    "    def construct_tokens_with_size(self, tokens: str, numofTokens: int) -> str:\n",
    "        newTokens = self.GPT2_TOKENIZER.decode(\n",
    "            self.GPT2_TOKENIZER.encode(tokens)[:numofTokens]\n",
    "        )\n",
    "        return newTokens\n",
    "\n",
    "parser_factory = ParserFactory()\n",
    "TOKEN_ESTIMATOR = TokenEstimator()\n",
    "\n",
    "def _get_file_format(file_name: str, extensions_to_process: List[str]) -> Optional[str]:\n",
    "    \"\"\"Gets the file format from the file name.\n",
    "    Returns None if the file format is not supported.\n",
    "    Args:\n",
    "        file_name (str): The file name.\n",
    "        extensions_to_process (List[str]): List of extensions to process.\n",
    "    Returns:\n",
    "        str: The file format.\n",
    "    \"\"\"\n",
    "\n",
    "    # in case the caller gives us a file path\n",
    "    file_name = os.path.basename(file_name)\n",
    "    file_extension = file_name.split(\".\")[-1]\n",
    "    if file_extension not in extensions_to_process:\n",
    "        return None\n",
    "    return FILE_FORMAT_DICT.get(file_extension, None)\n",
    "\n",
    "@dataclass\n",
    "class ChunkingResult:\n",
    "    \"\"\"Data model for chunking result\n",
    "\n",
    "    Attributes:\n",
    "        chunks (List[Document]): List of chunks.\n",
    "        total_files (int): Total number of files.\n",
    "        num_unsupported_format_files (int): Number of files with unsupported format.\n",
    "        num_files_with_errors (int): Number of files with errors.\n",
    "        skipped_chunks (int): Number of chunks skipped.\n",
    "    \"\"\"\n",
    "    chunks: List[Document]\n",
    "    total_files: int\n",
    "    num_unsupported_format_files: int = 0\n",
    "    num_files_with_errors: int = 0\n",
    "    # some chunks might be skipped to small number of tokens\n",
    "    skipped_chunks: int = 0\n",
    "\n",
    "def get_files_recursively(directory_path: str) -> List[str]:\n",
    "    \"\"\"Gets all files in the given directory recursively.\n",
    "    Args:\n",
    "        directory_path (str): The directory to get files from.\n",
    "    Returns:\n",
    "        List[str]: List of file paths.\n",
    "    \"\"\"\n",
    "    file_paths = []\n",
    "    for dirpath, _, files in os.walk(directory_path):\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(dirpath, file_name)\n",
    "            file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "def extract_pdf_content_regular(file_path):\n",
    "    docs = PDFReader().load_data(file=file_path)\n",
    "    full_text = \"\".join([doc.text for doc in docs])\n",
    "\n",
    "    return full_text\n",
    "\n",
    "def get_embedding(text):\n",
    "    try:\n",
    "        client = AzureOpenAI(\n",
    "            api_key = settings.AZURE_OPENAI_KEY,\n",
    "            api_version = settings.AZURE_OPENAI_PREVIEW_API_VERSION,\n",
    "            azure_endpoint = settings.AZURE_OPENAI_EMBEDDING_ENDPOINT\n",
    "        )\n",
    "\n",
    "        response = client.embeddings.create(\n",
    "            input=text,\n",
    "            model=\"text-embedding-ada-002\"\n",
    "        )\n",
    "        \n",
    "        embeddings = ast.literal_eval(response.json())[\"data\"][0][\"embedding\"]\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error getting embeddings with endpoint={settings.AZURE_OPENAI_EMBEDDING_ENDPOINT} with error={e}\")\n",
    "\n",
    "def chunk_content_helper(\n",
    "        content: str, \n",
    "        file_format: str, \n",
    "        file_name: Optional[str],\n",
    "        token_overlap: int,\n",
    "        num_tokens: int = 256,\n",
    "        extractor_llm = None\n",
    ") -> Generator[Tuple[str, int, Document], None, None]:\n",
    "    \n",
    "    if num_tokens is None:\n",
    "        num_tokens = 1000000000\n",
    "\n",
    "    parser = parser_factory(file_format)\n",
    "    doc = parser.parse(content, file_name=file_name)\n",
    "    llama_doc = LlamaDocument(text=doc.content, metadata={\"file_name\": file_name, \"title\": doc.title})\n",
    "\n",
    "    # if the original doc after parsing is < num_tokens return as it is\n",
    "    doc_content_size = TOKEN_ESTIMATOR.estimate_tokens(doc.content)\n",
    "\n",
    "    if file_format == \"json\" or doc_content_size < num_tokens:\n",
    "        yield doc.content, doc_content_size, doc\n",
    "    else:\n",
    "        llama_splitter = LlamaIndexSplitter(\n",
    "            num_tokens=settings.PREP_CONFIG[\"chunk_size\"], \n",
    "            token_overlap=settings.PREP_CONFIG[\"token_overlap\"], \n",
    "            extractor_llm=extractor_llm\n",
    "        )\n",
    "        nodes = llama_splitter.get_nodes_from_doc(llama_doc, settings.PREP_CONFIG.get(\"split_mods\", []))\n",
    "        print(\"split mods:\", settings.PREP_CONFIG.get(\"split_mods\", []))\n",
    "        \n",
    "        for node in nodes:\n",
    "            chunk_size = TOKEN_ESTIMATOR.estimate_tokens(node.text)\n",
    "            yield node, chunk_size, llama_doc\n",
    "\n",
    "def chunk_content(\n",
    "    content: str,\n",
    "    file_name: Optional[str] = None,\n",
    "    url: Optional[str] = None,\n",
    "    ignore_errors: bool = False,\n",
    "    num_tokens: int = 256,\n",
    "    min_chunk_size: int = 10,\n",
    "    token_overlap: int = 0,\n",
    "    extensions_to_process = FILE_FORMAT_DICT.keys(),\n",
    "    cracked_pdf = False,\n",
    "    use_json_parsing = False,\n",
    "    use_layout = False,\n",
    "    add_embeddings = False\n",
    ") -> ChunkingResult:\n",
    "    \"\"\"Chunks the given content. If ignore_errors is true, returns None\n",
    "        in case of an error\n",
    "    Args:\n",
    "        content (str): The content to chunk.\n",
    "        file_name (str): The file name. used for title, file format detection.\n",
    "        url (str): The url. used for title.\n",
    "        ignore_errors (bool): If true, ignores errors and returns None.\n",
    "        num_tokens (int): The number of tokens in each chunk.\n",
    "        min_chunk_size (int): The minimum chunk size below which chunks will be filtered.\n",
    "        token_overlap (int): The number of tokens to overlap between chunks.\n",
    "    Returns:\n",
    "        List[Document]: List of chunked documents.\n",
    "    \"\"\"\n",
    "    ignore_errors = False\n",
    "    try:\n",
    "        if use_json_parsing == True:\n",
    "            file_format = \"json\"\n",
    "        elif file_name is None or cracked_pdf == False or (cracked_pdf and not use_layout):\n",
    "            file_format = \"text\"\n",
    "        elif cracked_pdf:\n",
    "            file_format = \"html\"\n",
    "        else:\n",
    "            file_format = _get_file_format(file_name, extensions_to_process)\n",
    "            if file_format is None:\n",
    "                raise Exception(\n",
    "                    f\"{file_name} is not supported\")\n",
    "        \n",
    "        extractor_llm = LlamaAOAI(\n",
    "                model=settings.AZURE_OPENAI_MODEL_NAME,\n",
    "                deployment_name=settings.AZURE_OPENAI_MODEL,\n",
    "                api_key=settings.AZURE_OPENAI_KEY,\n",
    "                azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,\n",
    "                api_version=settings.AZURE_OPENAI_PREVIEW_API_VERSION,\n",
    "                system_prompt=settings.AZURE_OPENAI_SYSTEM_MESSAGE\n",
    "            )\n",
    "\n",
    "        nodes = chunk_content_helper(\n",
    "            content=content,\n",
    "            file_name=file_name,\n",
    "            file_format=file_format,\n",
    "            num_tokens=num_tokens,\n",
    "            token_overlap=token_overlap,\n",
    "            extractor_llm=extractor_llm\n",
    "        )\n",
    "        \n",
    "        chunks = []\n",
    "        skipped_chunks = 0\n",
    "        for node, chunk_size, llama_doc in nodes:\n",
    "            if chunk_size >= min_chunk_size:\n",
    "                if add_embeddings:\n",
    "                    for _ in range(RETRY_COUNT):\n",
    "                        try:\n",
    "                            combined_content = f\"{node.text}\\n\\nMETADATA: {node.metadata}\"\n",
    "                            contentVector = get_embedding(combined_content)\n",
    "                            break\n",
    "                        except:\n",
    "                            sleep(30)\n",
    "                    if contentVector is None:\n",
    "                        raise Exception(f\"Error getting embedding for chunk={node}\")\n",
    "                    \n",
    "\n",
    "                chunks.append(\n",
    "                    Document(\n",
    "                        id=node.id_,\n",
    "                        content=node.text,\n",
    "                        title=node.metadata[\"title\"],\n",
    "                        url=url,\n",
    "                        contentVector=contentVector,\n",
    "                        metadata=node.metadata\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                skipped_chunks += 1\n",
    "\n",
    "    except UnsupportedFormatError as e:\n",
    "        if ignore_errors:\n",
    "            return ChunkingResult(\n",
    "                chunks=[], total_files=1, num_unsupported_format_files=1\n",
    "            )\n",
    "        else:\n",
    "            raise e\n",
    "    except Exception as e:\n",
    "        if ignore_errors:\n",
    "            return ChunkingResult(chunks=[], total_files=1, num_files_with_errors=1)\n",
    "        else:\n",
    "            raise e\n",
    "    \n",
    "    return ChunkingResult(\n",
    "        chunks=chunks,\n",
    "        total_files=1,\n",
    "        skipped_chunks=skipped_chunks,\n",
    "    )\n",
    "\n",
    "def chunk_file(\n",
    "    file_path: str,\n",
    "    ignore_errors: bool = True,\n",
    "    num_tokens=256,\n",
    "    min_chunk_size=10,\n",
    "    url = None,\n",
    "    token_overlap: int = 0,\n",
    "    extensions_to_process = FILE_FORMAT_DICT.keys(),\n",
    "    use_layout = False,\n",
    "    add_embeddings=False\n",
    ") -> ChunkingResult:\n",
    "    \"\"\"Chunks the given file.\n",
    "    Args:\n",
    "        file_path (str): The file to chunk.\n",
    "    Returns:\n",
    "        List[Document]: List of chunked documents.\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_format = _get_file_format(file_name, extensions_to_process)\n",
    "    if not file_format:\n",
    "        if ignore_errors:\n",
    "            return ChunkingResult(\n",
    "                chunks=[], total_files=1, num_unsupported_format_files=1\n",
    "            )\n",
    "        else:\n",
    "            raise UnsupportedFormatError(f\"{file_name} is not supported\")\n",
    "\n",
    "    cracked_pdf = False\n",
    "    use_json_parsing = False\n",
    "    if file_format == \"pdf\":\n",
    "        content = extract_pdf_content_regular(file_path)\n",
    "    elif file_format == \"json\":\n",
    "        with open(file_path) as f:\n",
    "            content = json.load(f)\n",
    "        use_json_parsing = True\n",
    "        \n",
    "    return chunk_content(\n",
    "        content=content,\n",
    "        file_name=file_name,\n",
    "        ignore_errors=ignore_errors,\n",
    "        num_tokens=num_tokens,\n",
    "        min_chunk_size=min_chunk_size,\n",
    "        url=url,\n",
    "        token_overlap=max(0, token_overlap),\n",
    "        extensions_to_process=extensions_to_process,\n",
    "        cracked_pdf=cracked_pdf,\n",
    "        use_json_parsing=use_json_parsing,\n",
    "        use_layout=use_layout,\n",
    "        add_embeddings=add_embeddings\n",
    "    )\n",
    "\n",
    "\n",
    "def process_file(\n",
    "        file_path: str, # !IMP: Please keep this as the first argument\n",
    "        directory_path: str,\n",
    "        ignore_errors: bool = True,\n",
    "        num_tokens: int = 1024,\n",
    "        min_chunk_size: int = 10,\n",
    "        url_prefix = None,\n",
    "        token_overlap: int = 0,\n",
    "        extensions_to_process: List[str] = FILE_FORMAT_DICT.keys(),\n",
    "        form_recognizer_client = None,\n",
    "        use_layout = False,\n",
    "        add_embeddings = False\n",
    "    ):\n",
    "\n",
    "    is_error = False\n",
    "    try:\n",
    "        url_path = None\n",
    "        rel_file_path = os.path.relpath(file_path, directory_path)\n",
    "        if url_prefix:\n",
    "            url_path = url_prefix + rel_file_path\n",
    "            url_path = convert_escaped_to_posix(url_path)\n",
    "\n",
    "        result = chunk_file(\n",
    "            file_path,\n",
    "            ignore_errors=ignore_errors,\n",
    "            num_tokens=num_tokens,\n",
    "            min_chunk_size=min_chunk_size,\n",
    "            url=url_path,\n",
    "            token_overlap=token_overlap,\n",
    "            extensions_to_process=extensions_to_process,\n",
    "            use_layout=use_layout,\n",
    "            add_embeddings=add_embeddings\n",
    "        )\n",
    "        for chunk_idx, chunk_doc in enumerate(result.chunks):\n",
    "            chunk_doc.filepath = rel_file_path\n",
    "            chunk_doc.metadata[\"chunk_idx\"] = str(chunk_idx)\n",
    "    except Exception as e:\n",
    "        if not ignore_errors:\n",
    "            raise\n",
    "        print(f\"File ({file_path}) failed with \", e)\n",
    "        is_error = True\n",
    "        result =None\n",
    "    return result, is_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"../../data/full_data\"\n",
    "chunks = []\n",
    "total_files = 0\n",
    "num_unsupported_format_files = 0\n",
    "num_files_with_errors = 0\n",
    "skipped_chunks = 0\n",
    "\n",
    "all_files_directory = get_files_recursively(directory_path)\n",
    "files_to_process = [file_path for file_path in all_files_directory if os.path.isfile(file_path)]\n",
    "file_path = files_to_process[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: A web browser has been opened at https://login.microsoftonline.com/organizations/oauth2/v2.0/authorize. Please continue the login in the web browser. If no web browser is available or if the web browser fails to open, use device code flow with `az login --use-device-code`.\n",
      "WARNING: The following tenants don't contain accessible subscriptions. Use 'az login --allow-no-subscriptions' to have tenant level access.\n",
      "WARNING: 0ee6c63b-4eab-4748-b74a-d1dc22fc1a24 'Accenture Federal Services'\n",
      "WARNING: The following tenants require Multi-Factor Authentication (MFA). Use 'az login --tenant TENANT_ID' to explicitly login to a tenant.\n",
      "WARNING: 031d8bee-cd40-4791-b63c-bc890be44c22 'Default Directory'\n",
      "WARNING: e7064db9-cd6d-4c43-add3-3876707982b1 'AFS - SPROJ'\n",
      "ERROR: No subscriptions found for andre.chen@accenturefederal.com.\n"
     ]
    }
   ],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e34cc42db3d41b0ba7cee59aa70bec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split mods: ['summary_extraction']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result, is_error = process_file(file_path=file_path,\n",
    "                                directory_path=directory_path, \n",
    "                                ignore_errors=False,\n",
    "                                num_tokens=settings.PREP_CONFIG[\"chunk_size\"],\n",
    "                                min_chunk_size=100, \n",
    "                                url_prefix=None,\n",
    "                                token_overlap=settings.PREP_CONFIG[\"token_overlap\"],\n",
    "                                extensions_to_process=list(FILE_FORMAT_DICT.keys()),\n",
    "                                add_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(content=\".................... ................................ ................................ ................................ ................................ ............................... 8 \\nPersonnel Compensation and Benefits ................................ ................................ ................................ ................................ ................................ ........................ 9 \\nNon Pay Budget Exhibits ................................ ................................ ................................ ................................ ................................ ................................ .......... 12 \\n \\n Federal Emergency Management Agency Radiological Emergency Preparedness Program \\nFEMA – REPP - 3 Radiological Emergency Preparedness Program \\nBudget Comparison and Adjustments \\nComparison of Budget Authority and Request \\n(Dollars in Thousands) \\n \\n \\nFY 2022 \\nEnacted FY 2023 \\nEnacted FY 2024 \\nPresident's Budget FY 2023 to FY 2024 Total \\nChanges \\n \\nPos. FTE Amount Pos. FTE Amount Pos. FTE Amount Pos. FTE Amount \\nRadiological Emergency Preparedness Program 169 138 - 156 137 - 156 141 - - 4 - \\nTotal 169 138 - 156 137 - 156 141 - - 4 - \\nSubtotal Discretionary - Appropriation 169 138 - 156 137 - 156 141 - - 4 - \\n \\nThe Radiological Emergency Preparedness Program (REPP) was established by Executive Order 12657 to assist State, Local, Tribal and Territorial \\ngovernment in the development of off -site radiological emergency preparedness plans within the emergency planning zones of Nuclear Regulatory \\nCommission (NRC) licensed commercial nuclear power facilities. REP P has strengthened emergency preparedness capabilities for more than 500 \\ncommunities (35 States), or nearly 134 million residents located within the emergency planning zones of the Nation’s 57 Nucle ar Power Plants. \\n \\nThe FY 2024 Budget includes 156 positions, 141 FTE, and $36.0M in offsetting collections authority for FY 2024 operational requirements. FEMA \\nwill utilize $33.9M in previously unavailable FY 2023 offsetting collections for FY 2024 operating expenses in support of REP P. The net budget \\nauthority for REPP in FY 2024 is $0. \\n \\nFee Authority: 42 U.S.C\", id='bb67ccb1-0a84-4a62-bfb6-a0d24fee2404', title='Federal Emergency Management Agency                                                                                                             Radiological Emergency Preparedness Program', filepath='FEMA_REPP_REPP.pdf', url=None, metadata={'file_name': 'FEMA_REPP_REPP.pdf', 'title': 'Federal Emergency Management Agency                                                                                                             Radiological Emergency Preparedness Program', 'prev_section_summary': 'The key topics of this section are the Federal Emergency Management Agency (FEMA) Radiological Emergency Preparedness Program (REPP) and its budget for Fiscal Year 2024. The section includes a budget comparison and adjustments, a summary of budget changes, and justifications for pricing and program changes. The entities mentioned are the Department of Homeland Security and FEMA.', 'next_section_summary': 'The key topics of this section are the Federal Emergency Management Agency (FEMA) Radiological Emergency Preparedness Program (REPP) and its budget. The section discusses the budget authority for FY 2024, the fee authority and uses for the program, the change mechanism for assessing and collecting fees, previous changes in the methodology for calculating and issuing bills to licensees, and the historical collections and cost recovery rate for the program. The entities mentioned in the section include FEMA, the Nuclear Regulatory Commission (NRC) licensees, State, local, and industry officials, the Federal Radiological Preparedness Coordinating Committee (FRPCC), and the Regional Assistance Committees.', 'section_summary': \"The key topics of this section are the Federal Emergency Management Agency (FEMA) Radiological Emergency Preparedness Program (REPP) and its budget. The section discusses the budget comparison and adjustments for FY 2022, FY 2023, and the President's Budget for FY 2024. It mentions the number of positions and full-time equivalents (FTE) allocated for the program, as well as the offsetting collections authority and operational requirements. The section also highlights the purpose of the REPP, which is to assist state, local, tribal, and territorial governments in developing off-site radiological emergency preparedness plans for nuclear power facilities.\", 'chunk_idx': '1'}, contentVector=[-0.0017946918960660696, 0.0033382955007255077, -0.027987081557512283, -0.0209363866597414, -0.00465440284460783, -0.009780649095773697, 0.0044724056497216225, -0.009787390008568764, -0.03898778557777405, 0.012456677854061127, 0.003589383792132139, 0.009942424483597279, -0.009558209218084812, -0.0008560596033930779, -0.031519170850515366, -0.004384777508676052, 0.01733689196407795, 0.005426204763352871, -0.005732903257012367, -0.0009790760232135653, 3.659949652501382e-05, -0.009908721782267094, -0.02266198769211769, -0.0026322146877646446, 0.014357535168528557, -0.013717175461351871, 0.021987924352288246, -0.026328887790441513, 0.004526331089437008, 0.0064676315523684025, -0.01616402342915535, -0.0056317937560379505, 0.009032439440488815, -0.0022041848860681057, 0.00109198153950274, -0.0354287326335907, -0.006063194014132023, -0.01358910370618105, 0.04675298556685448, -0.03246285766363144, 0.013022891245782375, 0.036803822964429855, 0.003328184364363551, 0.0069495863281190395, -0.018051398918032646, 0.011560174636542797, 0.008392080664634705, -0.03246285766363144, -0.025789638981223106, 0.02463025040924549, 0.008108974434435368, 0.0025496419984847307, -0.014613678678870201, -0.02107119932770729, -0.0011779245687648654, -0.015125966630876064, 0.0022496841847896576, 0.010495156049728394, -0.0314922071993351, -0.021596968173980713, -0.004192669875919819, -0.011823059059679508, -0.04065946117043495, 0.003811824368312955, -0.001555399619974196, -0.018954642117023468, -0.008472967892885208, 0.013252072036266327, -0.01087937131524086, -0.009713242761790752, 0.04562056064605713, 0.026207556948065758, -0.003700604196637869, -0.020329730585217476, 0.03739699721336365, -0.002045780187472701, 0.005611571948975325, 0.005796939134597778, 0.021084681153297424, -0.0009192529832944274, 0.03661508485674858, -0.017862660810351372, -0.008250527083873749, -0.018887236714363098, 0.009551468305289745, -0.018010955303907394, -0.029281282797455788, 0.0034478306770324707, -0.009814352728426456, -0.015665216371417046, 0.016069654375314713, 0.031249545514583588, 0.01486982312053442, 0.023268643766641617, 0.010434490628540516, 0.01640668511390686, -0.015125966630876064, 0.04006628692150116, 0.014842860400676727, -0.057807616889476776, 0.004934138618409634, 0.030764220282435417, -0.03394579514861107, 0.002399663208052516, -0.013582362793385983, -0.012652156874537468, 0.017552591860294342, 0.007960679940879345, 0.0014020503731444478, -0.004728549625724554, -0.028688108548521996, -0.003983710426837206, -0.006851847283542156, -0.011641062796115875, -0.005918270442634821, -0.028553295880556107, 0.02825670689344406, -0.015516922809183598, 0.0067507377825677395, -0.007974161766469479, 0.027717458084225655, 0.03084510751068592, 0.025021206587553024, -0.01023901253938675, 0.04163011163473129, 0.00025782897137105465, 0.0051498389802873135, -0.011742171831429005, 0.028202783316373825, -0.012396012432873249, 0.006282264366745949, -0.012032018974423409, 0.04793933779001236, 0.00998286809772253, -0.017970511689782143, 0.027313020080327988, -0.008803258650004864, 0.023848338052630424, -0.038394611328840256, -0.0330829955637455, 0.03906867280602455, 0.011041146703064442, -0.017593035474419594, -0.007900014519691467, 0.010097458958625793, 0.015449516475200653, 0.01702682301402092, 0.016662828624248505, 0.013164443895220757, 0.005732903257012367, -0.02434714324772358, 0.011593878269195557, -0.02715124562382698, 0.028175819665193558, -0.02100379392504692, -0.04532397538423538, -0.031033845618367195, -0.005082432646304369, -0.002389552304521203, -0.039634887129068375, -0.0025445865467190742, -0.018523242324590683, 0.014667604118585587, 0.015018116682767868, -0.030332820490002632, 0.025088611990213394, -0.00356579152867198, -0.03332565724849701, -0.0015520292799919844, 0.0021704817190766335, -0.008567336946725845, 0.007246173918247223, -0.017431261017918587, 0.01906249299645424, -0.007394467480480671, 0.03095295839011669, -0.0073270611464977264, -0.00515320897102356, -0.025951413437724113, 0.0017154895467683673, 0.01992529258131981, 0.011769134551286697, 0.009470581077039242, 0.016258392482995987, -0.0020322990603744984, -0.009173993021249771, 0.035967983305454254, 0.01457323506474495, -0.01511248480528593, -0.010225530713796616, 0.017080748453736305, 0.029308244585990906, 0.005874456372112036, -0.01627187244594097, -0.6061171889305115, -0.010232271626591682, 0.0020474654156714678, -0.015449516475200653, 0.0104681933298707, 0.017390817403793335, 0.014397978782653809, -0.008904367685317993, -0.03807105869054794, 0.023807894438505173, 0.020639799535274506, -0.0026473812758922577, -0.0022985537070780993, -0.032651595771312714, -0.013703694567084312, -0.019830923527479172, -0.01412835344672203, -0.0027805084828287363, 0.025897487998008728, 0.003048448357731104, -0.034727707505226135, 0.013413847424089909, -0.0315730944275856, 0.002655806951224804, 0.008695408701896667, 0.0036163462791591883, 0.01455975417047739, -0.013926135376095772, 0.007643871009349823, 0.005375649780035019, -0.01636624149978161, 0.013872209936380386, 0.0040443758480250835, 3.2485345400345977e-06, 0.040983010083436966, 0.014344054274260998, -0.007549501955509186, -0.0008981885039247572, 0.027191689237952232, 0.029766608029603958, -0.01189720630645752, 0.006781070493161678, 0.0010523803066462278, 0.006872069090604782, -0.03639938309788704, 0.012369049713015556, 0.019183823838829994, 0.0014264851342886686, 0.02175874263048172, -0.006855217274278402, -0.004583626054227352, 0.002628844464197755, -0.026571551337838173, 0.016285354271531105, 0.01248364057391882, -0.006005898583680391, -0.003390535246580839, -0.029658757150173187, -0.007771942764520645, -0.010164865292608738, 0.005621682852506638, -0.003491644747555256, 0.00019558350322768092, -0.008931330405175686, -0.02514253742992878, 0.008580817840993404, -0.01972307451069355, 0.007084398530423641, 0.015462998300790787, -0.04133352264761925, -0.014451904222369194, 0.02887684479355812, -0.0014256425201892853, -0.015692180022597313, 0.014627160504460335, -0.009147030301392078, 0.014344054274260998, 0.0006647942936979234, 0.017363853752613068, 0.020599355921149254, 0.004233113490045071, 0.0014382812660187483, -0.019466931000351906, 0.009059402160346508, 0.0077247582376003265, -0.035941023379564285, 0.006073304917663336, -0.016811123117804527, 0.03025193326175213, 0.004984693601727486, -0.004067968111485243, -0.016905492171645164, -0.014910266734659672, -0.025816600769758224, 0.002817582106217742, 0.00445555429905653, -0.003210223512724042, 0.038772083818912506, 0.0051397280767560005, -0.03772054612636566, -0.00555090606212616, -0.012578009627759457, 0.009632355533540249, 0.002300238935276866, 0.01412835344672203, 0.030332820490002632, -0.01260497234761715, 0.005129617173224688, 0.018037917092442513, 0.008931330405175686, 2.4118804503814317e-05, 0.004519590176641941, -0.01505856029689312, -0.01602921076118946, 0.0029136359225958586, -0.03378402069211006, 0.026099706068634987, 0.01775481179356575, 0.0011880354722961783, -0.00632944842800498, 0.012645415961742401, -0.006255301646888256, 0.0173773355782032, -0.015826990827918053, 0.01455975417047739, 0.028175819665193558, 0.02591096982359886, -0.008621261455118656, 0.006723775062710047, 0.010158124379813671, -0.002153630368411541, -0.008358377031981945, 0.025573937222361565, 0.001791321556083858, 0.02936217002570629, 0.0016354445833712816, 0.015166410245001316, -0.020815055817365646, 0.003933155909180641, -0.05840079113841057, -0.004425221588462591, 0.007670833263546228, 0.004034264944493771, -0.015449516475200653, -0.017593035474419594, -0.008459486998617649, -0.01238253153860569, 0.019817443564534187, 0.0005169218056835234, 0.0063227079808712006, -0.0007368347723968327, -0.00454992288723588, 0.003602864919230342, -0.003710715100169182, 0.020262323319911957, 0.00025003511109389365, -0.009025699459016323, -0.007947199046611786, -0.022122737020254135, -0.005382390692830086, 0.0014483921695500612, -0.008533633314073086, -0.0213138610124588, -0.010798484086990356, -0.02697598934173584, 0.02058587409555912, -0.007900014519691467, 0.006413706578314304, 0.01979047991335392, -0.038906898349523544, -0.0016076394822448492, -0.002409774111583829, -0.013400365598499775, 0.008951552212238312, -0.003097318112850189, 0.03186968341469765, -0.007792164571583271, -0.029065582901239395, -0.009463840164244175, -0.004758882336318493, 0.013413847424089909, 0.011701728217303753, -0.01364302821457386, 0.006851847283542156, 0.01605617254972458, 0.022877687588334084, 0.0071585457772016525, -0.002455273410305381, -0.0006209802231751382, 0.024818988516926765, -0.013528438284993172, 0.019008567556738853, 0.021489117294549942, 0.012402753345668316, -0.00104058429133147, 0.002381126396358013, -0.019938774406909943, -0.0057059405371546745, -0.005416093394160271, 0.031060807406902313, 0.02987445704638958, -0.009355990216135979, 0.033622246235609055, -0.012638675048947334, -0.010751299560070038, -0.016325797885656357, 0.007185508031398058, -0.02376745082437992, 0.007259655278176069, 0.010798484086990356, 0.006073304917663336, -0.01654149778187275, -0.02949698269367218, -0.015031597577035427, -0.02314731292426586, -0.01023901253938675, -0.018321024253964424, 0.022594580426812172, -0.02518298104405403, -0.004620699677616358, 0.005921640433371067, -0.0027131023816764355, 0.0314922071993351, -0.000732200569473207, -0.015355147421360016, -0.013171184808015823, 0.011526471935212612, 0.012180312536656857, 0.007805645931512117, 0.01091307494789362, 0.004334222991019487, 0.033109959214925766, 0.0078932736068964, 0.006882179994136095, 0.03405364602804184, 0.011216402985155582, 0.015220335684716702, 0.0019025419605895877, 0.018806349486112595, 0.02321471832692623, 0.009295324794948101, 0.0007406263612210751, 0.029065582901239395, 0.004944249521940947, -3.509865564410575e-05, -0.01493722852319479, 0.03825979679822922, 0.017983991652727127, -0.019318636506795883, 0.01131077203899622, -0.0015646680258214474, 0.0209363866597414, -0.021960962563753128, 0.012092684395611286, 0.012537566013634205, 0.008877405896782875, 0.020262323319911957, 0.005712680984288454, 0.02777138166129589, 0.023268643766641617, 0.021704819053411484, 0.012948743999004364, 0.01354191917926073, -0.0189681239426136, 0.03011712059378624, -0.019628705456852913, -0.021327342838048935, -0.008850443176925182, -0.01636624149978161, 0.0017576183890923858, -0.020734168589115143, -0.007549501955509186, -0.0229046493768692, 0.004903805907815695, -0.006127229891717434, 0.0055475360713899136, 0.008156158030033112, 0.001098722219467163, 0.023268643766641617, -0.007313580252230167, -0.004499368369579315, -0.015031597577035427, 0.02849937044084072, 0.02489987574517727, -0.004843140486627817, 0.016379723325371742, -0.013097037561237812, 0.0015132706612348557, -0.001195618649944663, -0.006140710785984993, -0.020060105249285698, 0.032516784965991974, -0.04022806137800217, 0.02262154407799244, -0.0005354585591703653, -0.004499368369579315, 0.004826288670301437, 0.02061283588409424, -0.00019558350322768092, 0.0035152367781847715, 0.003626457182690501, 0.012584750540554523, -0.004849880933761597, -0.009713242761790752, 0.02742086909711361, -0.0008762814686633646, 0.005126246716827154, -0.03205842152237892, -0.021529562771320343, 0.013407106511294842, 0.03402668237686157, -0.014654122292995453, 0.021731780841946602, 0.012726303189992905, 0.008311192505061626, -0.0346737839281559, -0.016932453960180283, -0.0204780250787735, 0.007691055070608854, -0.0009470580844208598, -0.0010245753219351172, -0.017768291756510735, -0.005884567275643349, 0.015773067250847816, 0.07074961811304092, 0.0511748380959034, 0.003110799239948392, 0.02653110772371292, -0.0026979357935488224, -0.0005000702221877873, -0.008958293125033379, -0.025358237326145172, -0.00918747391551733, -0.017431261017918587, -0.00643392838537693, 0.024495437741279602, -0.00035135517828166485, 0.008290970697999, -0.0020070215687155724, -0.015274260193109512, 0.020019661635160446, -0.044784724712371826, -0.01207246258854866, -0.010535599663853645, -0.03599494695663452, -0.011182700283825397, 0.03440415859222412, 0.047642748802900314, 0.01469456683844328, -0.008904367685317993, 0.027960119768977165, 0.022877687588334084, 0.009457099251449108, 0.00227496144361794, -0.0016228059539571404, 0.03405364602804184, -0.0028782475274056196, 0.017458222806453705, -0.009376212023198605, -0.030521558597683907, 0.03254374489188194, -0.040524646639823914, 0.014910266734659672, 0.005325095262378454, 0.015503441914916039, 0.002564808586612344, -0.002726583508774638, -0.01377784088253975, 0.04802022501826286, -0.0031984273809939623, -0.015125966630876064, 0.0008168797357939184, 0.00989523995667696, -0.015570848248898983, 0.013211628422141075, 0.005628423299640417, -0.032381970435380936, 0.0025850303936749697, 0.014519310556352139, -0.0008333100122399628, 0.015206853859126568, -0.02365959994494915, -0.023565230891108513, -0.019911810755729675, -0.018294060602784157, -0.01965566724538803, 0.023996630683541298, -0.004381407517939806, -0.01457323506474495, 0.014667604118585587, -0.0027872491627931595, 0.023187756538391113, -0.023578712716698647, 0.014007022604346275, -0.009113327600061893, -0.045512713491916656, -0.037558771669864655, 0.009167252108454704, 0.022648505866527557, -0.013373403809964657, -0.007873051799833775, 0.005874456372112036, 0.007967420853674412, -0.02158348634839058, -0.008668445982038975, -0.02231147512793541, 0.016150541603565216, -0.015773067250847816, -0.010508636943995953, 0.016015728935599327, -0.008061789907515049, -0.004728549625724554, -0.024562843143939972, 0.019669149070978165, 0.002135093556717038, -0.015018116682767868, 0.031141696497797966, -0.007198989391326904, -0.0009563264320604503, 0.03912259638309479, -0.008944811299443245, 0.008331414312124252, -0.0030956328846514225, 0.01041426882147789, 0.00014323831419460475, 0.011135515756905079, -0.032651595771312714, -0.017458222806453705, 0.0015174836153164506, -0.007320320699363947, 0.01367673184722662, 0.015004634857177734, -0.005341946613043547, -0.005965454503893852, 0.004347704350948334, -0.002526049967855215, 0.020976830273866653, 0.011924169026315212, 0.012928522191941738, -0.0036230869591236115, 0.01168824639171362, 0.012308384291827679, -0.002490661572664976, -0.0052981325425207615, 0.004772363696247339, -0.003838786855340004, 0.021947480738162994, -0.0002066423330688849, -0.026059262454509735, 0.023336049169301987, 0.006558629684150219, -0.008405561558902264, -0.029577869921922684, 0.0029658759012818336, -0.007960679940879345, 0.03774750977754593, -0.003646678989753127, -0.03219323232769966, -0.014681085012853146, -0.014060947112739086, -0.03898778557777405, 0.0012773487251251936, -0.011411881074309349, 0.008580817840993404, 0.009693020954728127, -0.005038618575781584, 0.011081590317189693, 0.0018048027995973825, 0.05098609998822212, -0.02434714324772358, -0.0042398544028401375, -0.0007292515365406871, 0.0027569164521992207, 0.02417188696563244, 0.015220335684716702, 0.013117259368300438, -0.02576267533004284, 0.0029945233836770058, -0.018765905871987343, -0.013710434548556805, 0.014896784909069538, -0.01523381657898426, 0.022365400567650795, 0.005244207568466663, 0.01574610359966755, 0.014613678678870201, -0.012840894050896168, 0.00585423456504941, 0.00044361749314703047, 0.009355990216135979, 0.009295324794948101, -0.009800870902836323, -0.017943548038601875, -0.0012048870557919145, -0.006895661354064941, 0.014708047732710838, -0.03575228527188301, -0.022122737020254135, 0.020531948655843735, 0.023713525384664536, 0.004101671278476715, -0.01671675406396389, -0.012288162484765053, 0.00463755102828145, -0.003582643112167716, 0.013514956459403038, -0.023295605555176735, 0.003289425978437066, -0.02748827636241913, -0.006383373402059078, 0.017835699021816254, -0.0052981325425207615, 0.0315730944275856, 0.018428873270750046, -0.010225530713796616, -0.02140823006629944, 0.014424941502511501, 0.008587558753788471, 0.017256004735827446, -0.016110097989439964, -0.00555090606212616, -0.03408060967922211, -0.039257410913705826, 0.008742593228816986, 0.007900014519691467, 0.009693020954728127, -0.008628002367913723, -0.006447409745305777, -0.009780649095773697, -0.0020103920251131058, -0.00979413092136383, -0.009908721782267094, 0.011047887615859509, 0.0011989889899268746, -0.005281281191855669, -0.01118944026529789, -0.00038842862704768777, -0.025048168376088142, 0.017013341188430786, -0.01188372541218996, 0.004428591579198837, 0.022810280323028564, -0.004071338567882776, -0.010151384398341179, 0.023740487173199654, -0.023120349273085594, 0.0052981325425207615, 0.0033147032372653484, 0.030872071161866188, 0.013858729042112827, -0.015476479195058346, -0.032651595771312714, 0.012915041297674179, -0.009302064776420593, -0.0024586436338722706, 0.04324785992503166, 0.015206853859126568, -0.024886393919587135, -0.005574498325586319, 0.002854655496776104, 0.011721950024366379, -0.0026473812758922577, -0.03898778557777405, 0.03486252203583717, 0.008668445982038975, 0.0006424660095945001, -0.01377784088253975, 1.9932243958464824e-05, -0.019750036299228668, -0.022675467655062675, 0.001799747347831726, -0.008257267996668816, 0.0049408795312047005, -0.020949868485331535, -0.02527735009789467, 0.04163011163473129, 0.0059250108897686005, 0.007738239597529173, -0.0009529560920782387, -0.017566073685884476, 0.00721921119838953, -0.004172448068857193, -0.01443842239677906, -0.0009470580844208598, -0.013528438284993172, 0.035455696284770966, -0.019884848967194557, 0.017121192067861557, -0.005416093394160271, -0.022365400567650795, -0.006359781604260206, -0.01395309716463089, 0.0323280468583107, 0.024117963388562202, -0.006612554658204317, -0.011405140161514282, 0.007664092816412449, 0.0008880776003934443, -0.00396348861977458, 0.020046623423695564, -0.029470020905137062, 0.009976127184927464, -0.015085523016750813, 0.004297149367630482, 0.019803961738944054, -0.009120067581534386, -0.034107573330402374, -0.020558912307024002, -0.0013144222320988774, 0.0017879512161016464, -0.009234658442437649, 0.008331414312124252, 0.010009830817580223, -0.013076815754175186, -0.008385339751839638, 0.03305603563785553, 0.02542564459145069, 0.04122567176818848, 0.005564387422055006, -0.005810420494526625, -0.01077826227992773, 0.008493189699947834, -0.024805506691336632, 0.008520152419805527, -0.003950007259845734, 0.023079905658960342, -0.04090212285518646, 0.002625474240630865, -0.024158407002687454, -0.004849880933761597, 0.02828367054462433, -0.016258392482995987, -0.03491644561290741, -0.01278022862970829, -0.012416234239935875, 0.02140823006629944, -0.004822918679565191, -0.00436118571087718, 0.00953124649822712, -0.004799326416105032, -0.002207555342465639, -0.008001123555004597, -0.008567336946725845, 0.02372700721025467, 0.04152226075530052, 0.01567869819700718, 0.02852633222937584, -0.008803258650004864, 0.025169501081109047, -0.028688108548521996, -0.0012048870557919145, -0.0002913214557338506, 0.0029068952426314354, -0.005523943807929754, 0.005082432646304369, 0.0224462877959013, -0.03726218640804291, -0.03257070854306221, -0.011715209111571312, 0.006595703307539225, -0.01602921076118946, 0.0056419046595692635, 0.004833029583096504, 0.0028664516285061836, 0.010434490628540516, 0.0013851987896487117, -0.0028950991109013557, 0.0020862240344285965, -0.007731499150395393, -0.03612975776195526, 0.004883584100753069, -0.009315546602010727, 0.004900435451418161, -0.029685720801353455, -0.005628423299640417, 0.027933157980442047, 0.0013068390544503927, -0.013258812949061394, -0.010421008802950382, -0.015624772757291794, -0.044811688363552094, -0.009362730197608471, -0.034350235015153885, 0.026409775018692017, 0.03615672141313553, 0.01346777193248272, 0.014815897680819035, 0.02825670689344406, 0.008189861662685871, 0.005635164212435484, -0.00044530266313813627, -0.010751299560070038, 0.02593793161213398, -0.025236906483769417, 0.014276647940278053, 0.005311613902449608, -0.039527036249637604, -0.01149950921535492, 0.014478866010904312, -0.001110518234781921, 0.03375706076622009, 0.006588962860405445, -0.016258392482995987, 0.00015229603741317987, -0.0045229606330394745, 0.017431261017918587, 0.004425221588462591, 0.017148153856396675, 0.017768291756510735, -0.028795957565307617, 0.003274259390309453, 0.016689792275428772, 0.012240977957844734, 0.00010616487270453945, 6.7998707891092636e-06, 0.026895100250840187, -0.0043140011839568615, 0.014290128834545612, -0.012786968611180782, -0.010852409526705742, 0.005446426570415497, -0.029308244585990906, 0.014101391658186913, 0.00891110859811306, -0.005951973609626293, 0.0370195209980011, 0.023255161941051483, -0.016244910657405853, -0.017148153856396675, -0.015880916267633438, -0.03960792347788811, 0.0016253336798399687, 0.0100704962387681, 0.022837243974208832, 0.002927117282524705, -0.004047746304422617, 0.019332118332386017, 0.01830754242837429, -0.016123579815030098, -0.006117118988186121, -0.03278641030192375, -0.008264008909463882, 0.02251369319856167, 0.0034781633876264095, -0.024616768583655357, -0.01247015967965126, -0.03672293573617935, -0.040848199278116226, -0.014330572448670864, -0.021960962563753128, 0.004118523094803095, -0.015152929350733757, -0.009214436635375023, -0.02434714324772358, -0.04502738639712334, -0.030629407614469528, 0.026099706068634987, 0.02337649278342724, -0.006477742455899715, 0.04513523727655411, 0.18733550608158112, -0.0022614803165197372, 0.006976548582315445, 0.019466931000351906, -0.008446005173027515, 0.010852409526705742, 0.012827413156628609, 0.00949754286557436, -0.043571412563323975, 0.0014736695447936654, -0.024198850616812706, 0.0032624632585793734, -0.03281337022781372, 0.005554276518523693, 0.008095492608845234, 0.0015815196093171835, -0.036588121205568314, -0.02078809216618538, -0.022365400567650795, 0.026746807619929314, 0.015840472653508186, 0.01179609727114439, -0.021731780841946602, -0.008439265191555023, 0.01826709881424904, 0.0006925993948243558, -0.01802443526685238, 0.008216824382543564, 0.034377194941043854, -0.017458222806453705, -0.024872912093997, -0.03302907198667526, 0.002579974941909313, 0.0014290128601714969, -0.01910293661057949, -0.009848055429756641, -0.005011655855923891, -0.01868501678109169, -0.0008821795345284045, 0.010333380661904812, -0.012712822295725346, -0.0023356270976364613, 0.005220615305006504, -0.030764220282435417, 0.025034688413143158, 0.038394611328840256, -0.00583738274872303, -0.009234658442437649, -0.010259234346449375, -0.013980059884488583, -0.06719056516885757, 0.012847634963691235, 0.011148996651172638, 0.010576043277978897, -0.0014711418189108372, -0.005446426570415497, 0.03491644561290741, 0.006774330046027899, -0.017525630071759224, 0.04532397538423538, -0.007852829992771149, 0.02078809216618538, -0.035105183720588684, 0.0018233394948765635, -0.007057436276227236, 0.024845950305461884, -0.0010523803066462278, 0.014708047732710838, 0.008803258650004864, -0.037181299179792404, -0.032031457871198654, 0.0017845809925347567, -0.022014888003468513, -0.003446145448833704, -0.008250527083873749, -0.010346862487494946, 0.03364920988678932, 0.015206853859126568, 0.007205729838460684, 0.01747170463204384, -0.008931330405175686, -0.0046577733010053635, -0.008668445982038975, -0.008560596033930779, 0.023012500256299973, -0.013400365598499775, 0.01799747347831726, 0.0017491925973445177, -0.0002759444178082049, -0.021111642941832542, -0.0019463560311123729, 0.007374245673418045, -0.04435332491993904, 0.007974161766469479, -0.0031950571574270725, -0.0006555259460583329, 0.00712484261021018, -0.0005426204297691584, -0.01733689196407795, 0.02427973784506321, -0.0314922071993351, 0.08983907103538513, 0.013016150332987309, 0.00038758604205213487, -0.00138772651553154, -0.00047774193808436394, 0.0034343493171036243, 0.03982362151145935, 0.02376745082437992, -0.004310630727559328, 0.0005510462215170264, -0.02434714324772358, 0.004017413593828678, -0.013521697372198105, -0.00025572252343408763, 0.01118944026529789, 0.007731499150395393, -0.024333663284778595, 0.0076506114564836025, -0.010171606205403805, -0.015759585425257683, -0.03850245848298073, 0.0039061931893229485, -0.005220615305006504, -0.039985399693250656, -0.022837243974208832, -0.020289286971092224, -0.008938071317970753, 0.0014349109260365367, -0.031519170850515366, 0.0070978798903524876, -0.0016211207257583737, 0.03451200947165489, -5.961241913610138e-05, 0.01605617254972458, -0.01197135355323553, 0.0030669851694256067, -0.004863362293690443, -0.007246173918247223, 0.02673332579433918, 0.01346777193248272, 0.009120067581534386, 0.012584750540554523, 0.020976830273866653, 0.016379723325371742, -0.015004634857177734, 0.016528017818927765, 0.010886112228035927, -0.021286899223923683, -0.028607219457626343, -0.025304313749074936, -0.018469316884875298, 0.02828367054462433, -0.026018818840384483, 0.01633927971124649, -0.01764696091413498, 0.003008004743605852, -0.05716051533818245, 0.01523381657898426, 0.021596968173980713, -0.04545878618955612, -0.005871085915714502, 0.009329027496278286, -0.01654149778187275, -0.00543968565762043, -0.011937649920582771, -0.16954024136066437, 0.006892290897667408, 0.021853111684322357, 0.0028041007462888956, -0.00013544446846935898, 0.002891728887334466, 0.006053082644939423, -0.012045499868690968, -0.01296896580606699, -0.00743491156026721, 0.014371016062796116, 0.004121893085539341, -0.022823762148618698, -0.009733465500175953, 0.010926555842161179, 0.005480129737406969, -0.011391659267246723, 0.04462295025587082, 0.00104058429133147, 0.0008720685727894306, 0.018523242324590683, -0.030683333054184914, 0.012948743999004364, -0.018455836921930313, 0.006450779736042023, -0.0018974863924086094, -0.025857044383883476, 0.025641344487667084, 0.002320460742339492, 0.00257660448551178, -0.01775481179356575, 0.00047310773516073823, 0.03715433552861214, 0.03488948568701744, -0.003036652458831668, -0.004192669875919819, 0.014613678678870201, -0.0031040585599839687, -0.007812386378645897, 0.041737962514162064, 0.030036233365535736, 0.0004697374242823571, -0.009922202676534653, 0.001781210652552545, -0.023255161941051483, 0.014397978782653809, 0.02549304999411106, -0.010265974327921867, 0.0019025419605895877, -0.010259234346449375, 0.004334222991019487, -0.021165568381547928, -0.02686813846230507, -0.010508636943995953, 0.023389974609017372, 0.003045078134164214, -0.0162044670432806, -0.008843702264130116, 0.02500772476196289, -0.0114523246884346, -0.019979218021035194, -0.02631540782749653, 0.026099706068634987, -0.0307372584939003, 0.0060497126542031765, -0.05333184078335762, -0.016460610553622246, 0.013117259368300438, -0.021731780841946602, -0.00485325139015913, 0.009908721782267094, -0.013784581795334816, -0.017458222806453705, -0.006299115717411041, 0.016972897574305534, -0.008351637050509453, -0.019911810755729675, 0.019264711067080498, 0.017242522910237312, 0.010785003192722797, 0.035967983305454254, 0.03887993469834328, 0.004475776106119156, -0.01629883609712124, 0.013164443895220757, -0.005449796561151743, -0.004054487217217684, 0.019386041909456253, 0.04915264993906021, 0.00734728341922164, 0.016177503392100334, -0.01229490339756012, -0.001278191339224577, -0.02020839974284172, 0.0007503160159103572, 0.016703274101018906, -0.003636568086221814, -0.014883304014801979, -0.004977952688932419, -0.002765342127531767, 0.014290128834545612, -0.01747170463204384, -0.011870243586599827, 0.01279370952397585, 0.003545569721609354, -0.019386041909456253, -0.02127341739833355, 0.03461986035108566, 0.0209363866597414, -0.03561747074127197, -0.02321471832692623, -0.002827693009749055, 0.01455975417047739, 0.013858729042112827, 0.00939643383026123, 0.028903808444738388, 0.015099003911018372, -0.0009891869267448783, -0.0028883586637675762, 0.0002689931425265968, 0.046402473002672195, -0.0002911108313128352, -0.009962646290659904, 0.014505828730762005, -0.026234518736600876, -0.019466931000351906, -0.10137902945280075, -0.011304031126201153, -0.01364302821457386, 0.02724561281502247, -0.0008375228499062359, 0.011122033931314945, 0.003916304092854261, 0.026989469304680824, -0.009868277236819267, -0.0004206572484690696, 0.01051537785679102, -0.021974442526698112, -0.0041050417348742485, 0.017121192067861557, 0.020868981257081032, 0.004310630727559328, 0.018658054992556572, -0.024333663284778595, 0.019696110859513283, 0.026018818840384483, 0.00563853420317173, -0.024872912093997, -0.006315967533737421, -0.016770679503679276, 0.003383794566616416, 0.009200955741107464, -0.013413847424089909, -0.0037343071307986975, -0.01051537785679102, 0.010043533518910408, -0.004489257466048002, -0.01886027306318283, -0.012942003086209297, -0.009598652832210064, -0.004142115358263254, -0.014168797060847282, -0.03782839700579643, -0.01229490339756012, 0.004603848326951265, -0.025668306276202202, 0.020491505041718483, 0.00752928014844656, -0.004041005857288837, -0.03639938309788704, 0.0073270611464977264, -0.03356832265853882, -0.022581100463867188, 0.01927819289267063, 0.017525630071759224, -0.023079905658960342, -0.03340654820203781, -0.038421571254730225, -0.018846793100237846, 0.016244910657405853, -0.001305153826251626, -0.011378178372979164, -0.004111782182008028, 0.025533493608236313, -0.035455696284770966, -0.030198007822036743, -0.0022142957895994186, -0.004310630727559328, -0.017983991652727127, 0.017876142635941505, 0.007003511302173138, 0.015773067250847816, -0.015597810037434101, -0.026153631508350372, 0.013130741193890572, -0.013885690830647945, -0.006808033213019371, 0.019844405353069305, -0.020154474303126335, -0.0065417783334851265, -0.0543564148247242, 0.006117118988186121, -0.01197135355323553, -0.011641062796115875, 0.031519170850515366, -0.020221879705786705, -0.010144643485546112, -0.024805506691336632, 0.01247015967965126, 0.013966578990221024, 0.015018116682767868, 0.04570144787430763, 0.012449937872588634, -0.02396966889500618, 0.004893695004284382, 0.004789215512573719, -0.0068147736601531506, 0.0063429297879338264, 0.011917428113520145, -0.007778683211654425, 0.017903104424476624, 0.033864907920360565, -0.011243365705013275, 0.006524926517158747, -0.019601741805672646, 0.00643392838537693, -0.021354306489229202, 0.012180312536656857, -0.07538717240095139, 0.019871367141604424, 0.003835416631773114, -0.01744474284350872, -0.02262154407799244, 0.007906755432486534, 0.0169998612254858, 0.003318073460832238, 0.00820334255695343, 0.009996349923312664, -0.015031597577035427, 0.04464991018176079, -0.0035489399451762438, -0.01806487888097763, -0.028553295880556107, 0.00860103964805603, -0.007421430200338364, -0.0064811124466359615, 0.027339981868863106, 0.03273248299956322, -0.03022496961057186, 0.020424099639058113, 0.02483246847987175, 0.00022096617612987757, -0.001704536029137671, 0.007637130096554756, -0.005898048635572195, -0.004219632595777512, -0.005675607826560736, -0.026396295055747032, 0.017552591860294342, -0.007738239597529173, -0.03621064871549606, 0.008243786171078682, -0.004873473197221756, -0.01930515468120575, 0.0037241962272673845, -0.0026676030829548836, 0.02414492517709732, -0.01127706840634346, -0.023079905658960342, -0.016770679503679276, -0.005244207568466663, -0.03060244582593441, -0.005628423299640417, 0.017633479088544846, -0.001991855213418603, -0.011068109422922134, 0.006696812808513641, -0.0030770960729569197, 0.04575537517666817, 0.013831766322255135, -0.018091842532157898, -0.0017845809925347567, -0.0022395732812583447, -0.005159949883818626, 0.0030585594940930605, 0.00367364170961082, 0.02680073119699955, 0.003939896356314421, 0.019601741805672646, 0.017633479088544846, 0.003282685298472643, -0.016177503392100334, -0.015341666527092457, -0.019992699846625328, -0.009342508390545845, 0.01319140661507845, -0.011148996651172638, -0.02117905020713806, -0.03270551934838295, -0.024576324969530106, 0.024616768583655357, 0.023673081770539284, 0.01844235509634018, -0.00018589384853839874, -0.010528858751058578, 0.019075972959399223, -0.008843702264130116, 0.01886027306318283, 0.034377194941043854, -0.018347986042499542, -0.0094840619713068, 0.02310686931014061, -0.0011400084476917982, 0.009544727392494678, -0.01775481179356575, 0.022082293406128883, -0.02936217002570629, 0.023025980219244957, -0.01407442893832922, 0.02262154407799244, 0.020868981257081032, 0.013434069231152534, 0.011020924896001816, 0.014775454066693783, 0.03553658351302147, 0.033864907920360565, 0.03216627240180969, 0.03000926971435547, 0.0055812387727200985, -0.010434490628540516, 0.0021165567450225353, -0.019830923527479172, -0.00683836592361331, 0.009140290319919586, -0.032651595771312714, -0.016325797885656357, -0.006976548582315445, 0.03049459494650364, -0.005207134410738945, 0.007178767584264278, 0.009120067581534386, 0.008230305276811123, -0.03313692286610603, 0.0034680524840950966, -0.01965566724538803, -0.014451904222369194, -0.02103075571358204, 0.03135739639401436, 0.002827693009749055, 0.01523381657898426, 0.022823762148618698, 0.009173993021249771, 0.04314001277089119, 0.008290970697999, 0.018887236714363098, 0.00047900580102577806, -0.01216009072959423, 0.0019109677523374557, 0.012665637768805027, 0.03049459494650364, -0.03971577435731888, -0.03588709607720375, -0.029227357357740402, 0.021125124767422676, -0.018604129552841187, 0.012247718870639801, -0.00405111676082015, 0.0648178681731224, 0.017741329967975616, -0.01393961627036333, -0.0026810842100530863, 0.012524084188044071, 0.029227357357740402, -0.005820531398057938, 0.0022530544083565474, 0.0021772223990410566, -0.023646118119359016, 0.012497122399508953, -0.04402977600693703, 0.019871367141604424, -0.0077854241244494915, -0.00663951737806201, -0.013723916374146938, 0.020464543253183365, 0.03009015880525112, -0.011755652725696564, 0.005796939134597778, 0.017282966524362564, -0.011755652725696564, 0.02314731292426586, 0.015732623636722565, -0.04939531162381172, -0.014087909832596779, 0.03135739639401436, -0.002955764764919877, 0.014236203394830227, 0.0010742873419076204, 0.002844544593244791, 2.9753548005828634e-05, -0.007205729838460684, -0.013494734652340412, 0.018078360706567764, -0.014101391658186913, 0.008850443176925182, -0.005884567275643349, 0.004755512345582247, 0.010670412331819534, 0.008850443176925182, 0.01647409237921238, -0.014950710348784924, -0.029470020905137062, -0.005517202895134687, 0.0017559332773089409, -0.008614521473646164, -0.0036702712532132864, -0.040497686713933945])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.chunks[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1: \n",
    "### Try refactoring our indexing / retrieval / generation pipeline fully in LlamaIndex\n",
    "\n",
    "Current Issues:\n",
    "- Queries against the ACS vector store don't work, potentially need to specify additional arguments to have it work with vectors\n",
    "- Not clear whether a fully refactor using LlamaIndex for storage, retrieval, and response generation LlamaIndex query engine does not use natural language query transformations out of the box, whereas it is unclear whether this is done on Azure use your data API (https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/use-your-data?tabs=ai-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_service_name = settings.AZURE_SEARCH_SERVICE\n",
    "key = settings.AZURE_SEARCH_KEY\n",
    "cognitive_search_credential = AzureKeyCredential(key)\n",
    "service_endpoint = f\"https://{search_service_name}.search.windows.net\"\n",
    "index_name = settings.AZURE_SEARCH_INDEX\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=service_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=cognitive_search_credential\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores import CognitiveSearchVectorStore\n",
    "from llama_index.vector_stores.cogsearch import (\n",
    "    IndexManagement,\n",
    "    MetadataIndexFieldType,\n",
    "    CognitiveSearchVectorStore,\n",
    ")\n",
    "from llama_index.llms import AzureOpenAI\n",
    "from llama_index.embeddings import AzureOpenAIEmbedding\n",
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    ServiceContext,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "from llama_index import set_global_service_context\n",
    "from llama_index.vector_stores.types import (\n",
    "    ExactMatchFilter,\n",
    "    MetadataFilters,\n",
    "    VectorStore,\n",
    "    VectorStoreQuery,\n",
    "    VectorStoreQueryMode,\n",
    "    VectorStoreQueryResult,\n",
    ")\n",
    "\n",
    "from llama_index.query_engine import CitationQueryEngine\n",
    "from llama_index.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Storage Context\n",
    "\n",
    "vector_store = CognitiveSearchVectorStore(\n",
    "    search_or_index_client=search_client,\n",
    "    #index_management=IndexManagement.NO_VALIDATION,\n",
    "    id_field_key=settings.AZURE_SEARCH_ID_COLUMNS,\n",
    "    chunk_field_key=settings.AZURE_SEARCH_CONTENT_COLUMNS,\n",
    "    embedding_field_key=settings.AZURE_SEARCH_VECTOR_COLUMNS,\n",
    "    metadata_string_field_key=settings.AZURE_SEARCH_METADATA_COLUMNS,\n",
    "    doc_id_field_key=settings.AZURE_SEARCH_FILENAME_COLUMN\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Service Context\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"dep-embeddings\",\n",
    "    api_key=settings.AZURE_OPENAI_KEY,\n",
    "    azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=settings.AZURE_OPENAI_PREVIEW_API_VERSION\n",
    ")\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=settings.AZURE_OPENAI_MODEL_NAME,\n",
    "    deployment_name=settings.AZURE_OPENAI_MODEL,\n",
    "    api_key=settings.AZURE_OPENAI_KEY,\n",
    "    azure_endpoint=settings.AZURE_OPENAI_ENDPOINT,\n",
    "    api_version=settings.AZURE_OPENAI_PREVIEW_API_VERSION,\n",
    "    system_prompt=settings.AZURE_OPENAI_SYSTEM_MESSAGE\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(\n",
    "    [], storage_context=storage_context, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.memory import ChatMemoryBuffer\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=1500)\n",
    "chat_engine = index.as_chat_engine(chat_mode=\"context\", memory=memory, system_prompt=settings.AZURE_OPENAI_SYSTEM_MESSAGE, vector_store_query_mode=\"hybrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import openai\n",
    "\n",
    "class AOAIGenerator:\n",
    "    \"\"\"\n",
    "    A class for building and managing messages in a chat conversation.\n",
    "    Attributes:\n",
    "        message (list): A list of dictionaries representing chat messages.\n",
    "        model (str): The name of the GPT model.\n",
    "        token_count (int): The total number of tokens in the conversation.\n",
    "    Methods:\n",
    "        __init__(self, system_content: str, chatgpt_model: str): Initializes the MessageBuilder instance.\n",
    "        append_message(self, role: str, content: str, index: int = 1): Appends a new message to the conversation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, system_content: str, model: str = \"gpt-35-turbo\"):\n",
    "        \n",
    "        system_prompt = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": self.normalize_content(system_content),\n",
    "        }\n",
    "        self.messages = [system_prompt]\n",
    "        self.model = model\n",
    "        self.client = AOAI(\n",
    "            azure_endpoint = settings.AZURE_OPENAI_ENDPOINT, \n",
    "            api_key=settings.AZURE_OPENAI_KEY,  \n",
    "            api_version=settings.AZURE_OPENAI_PREVIEW_API_VERSION\n",
    "        )\n",
    "\n",
    "    def chat_completion(self, messages):\n",
    "        self.messages += messages\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=settings.AZURE_OPENAI_MODEL,\n",
    "            messages=self.messages,\n",
    "            temperature=settings.AZURE_OPENAI_TEMPERATURE,\n",
    "            max_tokens=settings.AZURE_OPENAI_MAX_TOKENS,\n",
    "            top_p=settings.AZURE_OPENAI_TOP_P,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None,\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            _ = response.choices[0].message.content\n",
    "            return response\n",
    "        except:\n",
    "            return \"\"\n",
    "\n",
    "    def normalize_content(self, content: str):\n",
    "        return unicodedata.normalize(\"NFC\", content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am FEMA OCFO GPT, a helpful AI assistant. My purpose is to provide accurate and relevant information about the FEMA budget. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "test = AOAIGenerator(settings.AZURE_OPENAI_SYSTEM_MESSAGE, model=settings.AZURE_OPENAI_MODEL_NAME)\n",
    "test_messages = [\n",
    "    {\"role\": \"user\", \"content\": \"who are you?\"}\n",
    "]\n",
    "response = test.chat_completion(test_messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Response\n",
    "def format_as_ndjson(obj: dict) -> str:\n",
    "    return json.dumps(obj, ensure_ascii=False) + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ContextChatEngine' object has no attribute 'get_prompts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prompts \u001b[39m=\u001b[39m chat_engine\u001b[39m.\u001b[39;49mget_prompts()\n\u001b[0;32m      2\u001b[0m prompts\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ContextChatEngine' object has no attribute 'get_prompts'"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import datetime\n",
    "\n",
    "from typing import Any, List, Optional, Sequence\n",
    "from llama_index.core import BaseQueryEngine, BaseRetriever\n",
    "from llama_index.callbacks.base import CallbackManager\n",
    "from llama_index.postprocessor.types import BaseNodePostprocessor\n",
    "from llama_index.response.schema import RESPONSE_TYPE\n",
    "from llama_index.callbacks.schema import CBEventType, EventPayload\n",
    "from llama_index.node_parser import SentenceSplitter, TextSplitter\n",
    "from llama_index.prompts.base import BasePromptTemplate\n",
    "from llama_index.response_synthesizers import (\n",
    "    BaseSynthesizer,\n",
    "    ResponseMode,\n",
    "    get_response_synthesizer,\n",
    ")\n",
    "from llama_index.indices.base import BaseGPTIndex\n",
    "from llama_index.schema import MetadataMode, NodeWithScore, QueryBundle\n",
    "from llama_index.retrievers import BM25Retriever, QueryFusionRetriever\n",
    "from llama_index.response.schema import Response\n",
    "\n",
    "\n",
    "CITATION_QA_TEMPLATE = PromptTemplate(\n",
    "    \"Please provide an answer based solely on the provided sources. \"\n",
    "    \"When referencing information from a source, \"\n",
    "    \"cite the appropriate source(s) using their corresponding numbers. \"\n",
    "    \"Every answer should include at least one source citation. \"\n",
    "    \"Only cite a source when you are explicitly referencing it. \"\n",
    "    \"If none of the sources are helpful, you should indicate that. \"\n",
    "    \"For example:\\n\"\n",
    "    \"Source 1:\\n\"\n",
    "    \"The sky is red in the evening and blue in the morning.\\n\"\n",
    "    \"Source 2:\\n\"\n",
    "    \"Water is wet when the sky is red.\\n\"\n",
    "    \"Query: When is water wet?\\n\"\n",
    "    \"Answer: Water will be wet when the sky is red [2], \"\n",
    "    \"which occurs in the evening [1].\\n\"\n",
    "    \"Now it's your turn. Below are several numbered sources of information:\"\n",
    "    \"\\n------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n------\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "\n",
    "CITATION_REFINE_TEMPLATE = PromptTemplate(\n",
    "    \"Please provide an answer based solely on the provided sources. \"\n",
    "    \"When referencing information from a source, \"\n",
    "    \"cite the appropriate source(s) using their corresponding numbers. \"\n",
    "    \"Every answer should include at least one source citation. \"\n",
    "    \"Only cite a source when you are explicitly referencing it. \"\n",
    "    \"If none of the sources are helpful, you should indicate that. \"\n",
    "    \"For example:\\n\"\n",
    "    \"Source 1:\\n\"\n",
    "    \"The sky is red in the evening and blue in the morning.\\n\"\n",
    "    \"Source 2:\\n\"\n",
    "    \"Water is wet when the sky is red.\\n\"\n",
    "    \"Query: When is water wet?\\n\"\n",
    "    \"Answer: Water will be wet when the sky is red [2], \"\n",
    "    \"which occurs in the evening [1].\\n\"\n",
    "    \"Now it's your turn. \"\n",
    "    \"We have provided an existing answer: {existing_answer}\"\n",
    "    \"Below are several numbered sources of information. \"\n",
    "    \"Use them to refine the existing answer. \"\n",
    "    \"If the provided sources are not helpful, you will repeat the existing answer.\"\n",
    "    \"\\nBegin refining!\"\n",
    "    \"\\n------\\n\"\n",
    "    \"{context_msg}\"\n",
    "    \"\\n------\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "\n",
    "class BaseOCFOQueryEngine(BaseQueryEngine):\n",
    "    def __init__(\n",
    "        self,\n",
    "        retriever: BaseRetriever,\n",
    "        generator: AOAIGenerator,\n",
    "        node_postprocessors: Optional[List[BaseNodePostprocessor]] = None,\n",
    "        callback_manager: Optional[CallbackManager] = None,\n",
    "        metadata_mode: MetadataMode = MetadataMode.NONE,\n",
    "        citation_qa_template: BasePromptTemplate = CITATION_QA_TEMPLATE,\n",
    "        citation_refine_template: BasePromptTemplate = CITATION_REFINE_TEMPLATE,\n",
    "    ):\n",
    "        self._retriever = retriever\n",
    "        self._generator = generator\n",
    "        self._node_postprocessors = node_postprocessors or []\n",
    "        self._metadata_mode = metadata_mode\n",
    "        self.citation_qa_template = citation_qa_template\n",
    "        self.citation_refine_template = citation_refine_template\n",
    "\n",
    "        callback_manager = callback_manager or CallbackManager()\n",
    "        for node_postprocessor in self._node_postprocessors:\n",
    "            node_postprocessor.callback_manager = callback_manager\n",
    "\n",
    "        super().__init__(callback_manager)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_args(\n",
    "        cls,\n",
    "        index: VectorStoreIndex,\n",
    "        query_type: str,\n",
    "        citation_qa_template: BasePromptTemplate = CITATION_QA_TEMPLATE,\n",
    "        citation_refine_template: BasePromptTemplate = CITATION_REFINE_TEMPLATE,\n",
    "        node_postprocessors: Optional[List[BaseNodePostprocessor]] = None,\n",
    "        \n",
    "        # class-specific args\n",
    "        metadata_mode: MetadataMode = MetadataMode.NONE,\n",
    "        **kwargs: Any,\n",
    "    ) -> \"BaseOCFOQueryEngine\":\n",
    "\n",
    "        #TODO: Make this more generalizable and allow retrievers to be set outside of class definition\n",
    "        vector_retriever = index.as_retriever(similarity_top_k=settings.AZURE_SEARCH_TOP_K)\n",
    "        bm25_retriever = BM25Retriever.from_defaults(\n",
    "            docstore=index.docstore, similarity_top_k=settings.AZURE_SEARCH_TOP_K\n",
    "        )\n",
    "        rrf_retriever = QueryFusionRetriever(\n",
    "            [vector_retriever, bm25_retriever],\n",
    "            similarity_top_k=settings.AZURE_SEARCH_TOP_K,\n",
    "            num_queries=1,  # set this to 1 to disable query generation\n",
    "            mode=\"reciprocal_rerank\",\n",
    "            use_async=True,\n",
    "            verbose=True,\n",
    "            # query_gen_prompt=\"...\",  # we could override the query generation prompt here\n",
    "        )\n",
    "\n",
    "        retriever_mapping = {\n",
    "            \"simple\": bm25_retriever,\n",
    "            \"semantic\": bm25_retriever,\n",
    "            \"vector\": vector_retriever,\n",
    "            \"vectorSimpleHybrid\": rrf_retriever,\n",
    "            \"vectorSemanticHybrid\": rrf_retriever\n",
    "        }\n",
    "\n",
    "        return cls(\n",
    "            retriever=retriever_mapping[query_type],\n",
    "            callback_manager=index.service_context.callback_manager,\n",
    "            node_postprocessors=node_postprocessors,\n",
    "            metadata_mode=metadata_mode,\n",
    "            citation_qa_template=citation_qa_template,\n",
    "            citation_refine_template=citation_refine_template\n",
    "        )\n",
    "    \n",
    "    def retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        nodes = self._retriever.retrieve(query_bundle)\n",
    "\n",
    "        for postprocessor in self._node_postprocessors:\n",
    "            nodes = postprocessor.postprocess_nodes(nodes, query_bundle=query_bundle)\n",
    "\n",
    "        return nodes\n",
    "    \n",
    "    @property\n",
    "    def retriever(self) -> BaseRetriever:\n",
    "        \"\"\"Get the retriever object.\"\"\"\n",
    "        return self._retriever\n",
    "\n",
    "    def query(self, messages: List[dict]):\n",
    "        str_or_query_bundle = messages[-1][\"content\"]\n",
    "        with self.callback_manager.as_trace(\"query\"):\n",
    "            if isinstance(str_or_query_bundle, str):\n",
    "                str_or_query_bundle = QueryBundle(str_or_query_bundle)\n",
    "            return self._query(str_or_query_bundle, messages)\n",
    "\n",
    "\n",
    "    def _get_response(self, source_nodes, messages):\n",
    "        query_str = messages[-1][\"content\"]\n",
    "        context_str = \"\\n\\n\".join([n.node.get_content() for n in source_nodes])\n",
    "        aoai_generator = self._generator(\n",
    "            system_message=settings.AZURE_OPENAI_SYSTEM_MESSAGE,\n",
    "            model=settings.AZURE_OPENAI_MODEL_NAME\n",
    "        )\n",
    "        messages[-1][\"content\"] = self.citation_qa_template.format(context_str=context_str, query_str=query_str)\n",
    "        \n",
    "        return self._format_response(aoai_generator.chat_completion(messages), source_nodes)\n",
    "    \n",
    "        \n",
    "    def _format_response(self, aoai_response: dict, source_nodes: List[NodeWithScore]):\n",
    "        citations_json = [\n",
    "            {\n",
    "                \"content\": ct.node.text,\n",
    "                \"id\": \"\",\n",
    "                \"title\": \"\",\n",
    "                \"filepath\": \"\",\n",
    "                \"url\": \"\",\n",
    "                \"metadata\": ct.node.metadata\n",
    "            } for ct in source_nodes\n",
    "        ]\n",
    "\n",
    "        output_json = {\n",
    "            \"id\": aoai_response.id,\n",
    "            \"model\": settings.AZURE_OPENAI_MODEL_NAME,\n",
    "            \"created\": (datetime.now() - datetime(1970, 1, 1)).total_seconds(),\n",
    "            \"object\": \"chat.completion\",\n",
    "            \"choices\": [\n",
    "                {\n",
    "                    'index': 0,\n",
    "                    'messages': [\n",
    "                        {\n",
    "                            'index': 0,\n",
    "                            'role': 'tool',\n",
    "                            'content': {\n",
    "                                'citations': citations_json,\n",
    "                                'intent': ''\n",
    "                            },\n",
    "                            'end_turn': False\n",
    "                        },\n",
    "                        {\n",
    "                            'index': 1,\n",
    "                            'role': 'assistant',\n",
    "                            'content': aoai_response.choices[0].message.content,\n",
    "                            'end_turn': True\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            # TODO: add function to compute tokens used\n",
    "            \"usage\": {\"prompt_tokens\": 0, \"completion_tokens\": 0, \"total_tokens\": 0},\n",
    "            \"history_metadata\": {}\n",
    "        }\n",
    "\n",
    "        return output_json\n",
    "    \n",
    "    def _query(self, query_bundle: QueryBundle, messages: List[dict]) -> RESPONSE_TYPE:\n",
    "        \"\"\"Answer a query.\"\"\"\n",
    "        with self.callback_manager.event(\n",
    "            CBEventType.QUERY, payload={EventPayload.QUERY_STR: query_bundle.query_str}\n",
    "        ) as query_event:\n",
    "            with self.callback_manager.event(\n",
    "                CBEventType.RETRIEVE,\n",
    "                payload={EventPayload.QUERY_STR: query_bundle.query_str},\n",
    "            ) as retrieve_event:\n",
    "                nodes = self.retrieve(query_bundle)\n",
    "                retrieve_event.on_end(payload={EventPayload.NODES: nodes})\n",
    "\n",
    "            context_str = \"\\n\\n\".join([n.node.get_content() for n in nodes])\n",
    "            aoai_generator = self._generator(\n",
    "                system_message=settings.AZURE_OPENAI_SYSTEM_MESSAGE,\n",
    "                model=settings.AZURE_OPENAI_MODEL_NAME\n",
    "            )\n",
    "            messages[-1][\"content\"] = self.citation_qa_template.format(context_str=context_str, query_str=query_bundle.query_str)\n",
    "\n",
    "            query_event.on_end(payload={EventPayload.RESPONSE: response})\n",
    "\n",
    "        return response\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide an answer based solely on the provided sources. When referencing information from a source, cite the appropriate source(s) using their corresponding numbers. Every answer should include at least one source citation. Only cite a source when you are explicitly referencing it. If none of the sources are helpful, you should indicate that. For example:\n",
      "Source 1:\n",
      "The sky is red in the evening and blue in the morning.\n",
      "Source 2:\n",
      "Water is wet when the sky is red.\n",
      "Query: When is water wet?\n",
      "Answer: Water will be wet when the sky is red [2], which occurs in the evening [1].\n",
      "Now it's your turn. Below are several numbered sources of information:\n",
      "------\n",
      "hello\n",
      "------\n",
      "Query: goodbye\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "print(CITATION_QA_TEMPLATE.format(context_str=\"hello\", query_str=\"goodbye\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The PPAs (Program, Project, or Activity) within Operations and Support are as follows:\n",
       "\n",
       "1. Preparedness and Protection (PPA code: FEMA - O&S - 85) [Source 1]\n",
       "2. Response and Recovery (PPA code: FEMA - O&S - 86) [Source 1]\n",
       "3. Response (PPA code: FEMA - O&S - 96) [Source 2]\n",
       "4. Response (PPA code: FEMA - O&S - 97) [Source 2]\n",
       "5. Mission Support (PPA code: FEMA - O&S - 49) [Source 3]\n",
       "6. Mission Support (PPA code: FEMA - O&S - 50) [Source 3]\n",
       "\n",
       "Please note that these PPAs are specific to the FEMA Operations and Support budget.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "query_mode_mapping = {\n",
    "    \"simple\": \"text_search\",\n",
    "    \"vector\": \"default\",\n",
    "    \"vectorSimpleHybrid\": \"hybrid\",\n",
    "    \"vectorSemanticHybrid\": \"semantic_hybrid\"\n",
    "}\n",
    "\n",
    "query_engine = CitationQueryEngine.from_args(index, \n",
    "                                             similarity_top_k=settings.AZURE_SEARCH_TOP_K, \n",
    "                                             citation_chunk_size=settings.PREP_CONFIG[\"chunk_size\"],\n",
    "                                             vector_store_query_mode=query_mode_mapping[settings.AZURE_SEARCH_QUERY_TYPE])\n",
    "\n",
    "qe_response = query_engine.query(\"What are the PPAs within Operations and Support?\")\n",
    "\n",
    "display(Markdown(f\"<b>{qe_response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"node\": {\n",
      "      \"id_\": \"56\",\n",
      "      \"embedding\": null,\n",
      "      \"metadata\": {\n",
      "         \"chunk_id\": \"56\"\n",
      "      },\n",
      "      \"excluded_embed_metadata_keys\": [],\n",
      "      \"excluded_llm_metadata_keys\": [],\n",
      "      \"relationships\": {},\n",
      "      \"hash\": \"6005d11cb8f1053002578eb2971fa74a85db4e02db2d10362f5c0844f31ffce1\",\n",
      "      \"text\": \"Source 1:\\n. Operations and Support Preparedness and Protection \\u2013 PPA \\nFEMA \\u2013 O&S - 85 \\nNational Preparedness Directorate (NPD): NPD is instrumental in building a culture of preparedness across the Nation, with a focus on helping \\npeople prepare for disasters, organizing a scalable and capable incident workforce, lessons learned and continuous improvement . NPD will also \\ncontinue to provide doctrine, programs, and resources to implement the National Preparedness System which prepares the Nation to prevent, protect, \\nmitigate, respond to and recover from disasters. Activities include training, edu cation, and evaluation, support to the National Incident Management \\nSystem, technical assistance, assessing levels of national preparedness, national exercise leadership and support, Individual and Community \\nPreparedness, and executive oversight. The FY 20 24 Budget includes decreases for non -recurs from the FY 2023 Enacted. \\nResilience Offices: The Resilience Offices include the Office of Deputy Administrator, Resilience Enterprise Offices, Office of Resilience \\nIntegration and Coordination, Office of Law Enforcement Engagement and Integration, and Office of Counterterrorism and Securi ty Prepared ness. \\nThese Offices are responsible for setting and tracking strategic, programmatic and business process -related priorities for the Resilience directorates, \\nworking with the 10 FEMA Regions to implement a culture of preparedness and FEMA Integration Teams , and coordinating prevention -related \\npreparedness (e.g., complex coordinated attack, active shooter, etc.) activities across the whole community. The FY 2024 Budg et includes increases \\nfor the Climate Adaptation Office and a transfer for the Road to Resili ence Reorganization. Operations and Support Response and Recovery \\u2013 PPA \\nFEMA \\u2013 O&S - 86 Response and Recovery \\u2013 PPA \\nBudget Comparison and Adjustments \\nComparison of Budget Authority and Request \\n(Dollars in Thousands) \\n FY 2022 Enacted FY 2023 Enacted FY 2024 President's Budget FY 2023 to FY 2024 Total Changes \\n Pos. FTE Amount Pos. FTE Amount Pos. FTE Amount Pos. FTE Amount Response 855 759 $211,183 896 806 $222,496 917 837 $234,861 21 31 $12,365 Recovery 342 293 $55,186 346 243 $62,061 346 283 $57,427 - 40 ($4,634) Total 1,197 1,052 $266,369 1,242 1,049 $284,557 1,263 1,120 $292,288 21 71 $7,731 Subtotal Discretionary - Appropriation 1,197 1,052 $266,369 1,242 1,049 $284,557 1,263 1,120 $292,288 21 71 $7,731 \\nPPA Level I Description \\n \\nThe Office of Response and Recovery provides leadership to build, sustain, and improve the coordination and delivery of support to citizens and \\nState, local, tribal and territorial governments to save lives, reduce suffering, protect property and recover from all hazards. \\n \\nResponse leads and coordinates efforts to maintain the core Federal disaster response operational capabilities necessary to respond to and stabi lize the \\neffects of incidents, including all hazards planning, disaster emergency communications, response teams, logistics capabi lities and the disaster \\nworkforce. Recovery provides disaster survivors and communities recovering from disasters with disaster assistance grants, resources, and support\\n\",\n",
      "      \"start_char_idx\": null,\n",
      "      \"end_char_idx\": null,\n",
      "      \"text_template\": \"{metadata_str}\\n\\n{content}\",\n",
      "      \"metadata_template\": \"{key}: {value}\",\n",
      "      \"metadata_seperator\": \"\\n\",\n",
      "      \"class_name\": \"TextNode\"\n",
      "   },\n",
      "   \"score\": 0.03253968432545662,\n",
      "   \"class_name\": \"NodeWithScore\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NodeWithScore(node=TextNode(id_='56', embedding=None, metadata={'chunk_id': '56'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, hash='6005d11cb8f1053002578eb2971fa74a85db4e02db2d10362f5c0844f31ffce1', text=\"Source 1:\\n. Operations and Support Preparedness and Protection – PPA \\nFEMA – O&S - 85 \\nNational Preparedness Directorate (NPD): NPD is instrumental in building a culture of preparedness across the Nation, with a focus on helping \\npeople prepare for disasters, organizing a scalable and capable incident workforce, lessons learned and continuous improvement . NPD will also \\ncontinue to provide doctrine, programs, and resources to implement the National Preparedness System which prepares the Nation to prevent, protect, \\nmitigate, respond to and recover from disasters. Activities include training, edu cation, and evaluation, support to the National Incident Management \\nSystem, technical assistance, assessing levels of national preparedness, national exercise leadership and support, Individual and Community \\nPreparedness, and executive oversight. The FY 20 24 Budget includes decreases for non -recurs from the FY 2023 Enacted. \\nResilience Offices: The Resilience Offices include the Office of Deputy Administrator, Resilience Enterprise Offices, Office of Resilience \\nIntegration and Coordination, Office of Law Enforcement Engagement and Integration, and Office of Counterterrorism and Securi ty Prepared ness. \\nThese Offices are responsible for setting and tracking strategic, programmatic and business process -related priorities for the Resilience directorates, \\nworking with the 10 FEMA Regions to implement a culture of preparedness and FEMA Integration Teams , and coordinating prevention -related \\npreparedness (e.g., complex coordinated attack, active shooter, etc.) activities across the whole community. The FY 2024 Budg et includes increases \\nfor the Climate Adaptation Office and a transfer for the Road to Resili ence Reorganization. Operations and Support Response and Recovery – PPA \\nFEMA – O&S - 86 Response and Recovery – PPA \\nBudget Comparison and Adjustments \\nComparison of Budget Authority and Request \\n(Dollars in Thousands) \\n FY 2022 Enacted FY 2023 Enacted FY 2024 President's Budget FY 2023 to FY 2024 Total Changes \\n Pos. FTE Amount Pos. FTE Amount Pos. FTE Amount Pos. FTE Amount Response 855 759 $211,183 896 806 $222,496 917 837 $234,861 21 31 $12,365 Recovery 342 293 $55,186 346 243 $62,061 346 283 $57,427 - 40 ($4,634) Total 1,197 1,052 $266,369 1,242 1,049 $284,557 1,263 1,120 $292,288 21 71 $7,731 Subtotal Discretionary - Appropriation 1,197 1,052 $266,369 1,242 1,049 $284,557 1,263 1,120 $292,288 21 71 $7,731 \\nPPA Level I Description \\n \\nThe Office of Response and Recovery provides leadership to build, sustain, and improve the coordination and delivery of support to citizens and \\nState, local, tribal and territorial governments to save lives, reduce suffering, protect property and recover from all hazards. \\n \\nResponse leads and coordinates efforts to maintain the core Federal disaster response operational capabilities necessary to respond to and stabi lize the \\neffects of incidents, including all hazards planning, disaster emergency communications, response teams, logistics capabi lities and the disaster \\nworkforce. Recovery provides disaster survivors and communities recovering from disasters with disaster assistance grants, resources, and support\\n\", start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.03253968432545662)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(json.dumps(qe_response.source_nodes[0].to_dict(), indent=3))\n",
    "qe_response.source_nodes[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': \"Source 1:\\n. Operations and Support Preparedness and Protection – PPA \\nFEMA – O&S - 85 \\nNational Preparedness Directorate (NPD): NPD is instrumental in building a culture of preparedness across the Nation, with a focus on helping \\npeople prepare for disasters, organizing a scalable and capable incident workforce, lessons learned and continuous improvement . NPD will also \\ncontinue to provide doctrine, programs, and resources to implement the National Preparedness System which prepares the Nation to prevent, protect, \\nmitigate, respond to and recover from disasters. Activities include training, edu cation, and evaluation, support to the National Incident Management \\nSystem, technical assistance, assessing levels of national preparedness, national exercise leadership and support, Individual and Community \\nPreparedness, and executive oversight. The FY 20 24 Budget includes decreases for non -recurs from the FY 2023 Enacted. \\nResilience Offices: The Resilience Offices include the Office of Deputy Administrator, Resilience Enterprise Offices, Office of Resilience \\nIntegration and Coordination, Office of Law Enforcement Engagement and Integration, and Office of Counterterrorism and Securi ty Prepared ness. \\nThese Offices are responsible for setting and tracking strategic, programmatic and business process -related priorities for the Resilience directorates, \\nworking with the 10 FEMA Regions to implement a culture of preparedness and FEMA Integration Teams , and coordinating prevention -related \\npreparedness (e.g., complex coordinated attack, active shooter, etc.) activities across the whole community. The FY 2024 Budg et includes increases \\nfor the Climate Adaptation Office and a transfer for the Road to Resili ence Reorganization. Operations and Support Response and Recovery – PPA \\nFEMA – O&S - 86 Response and Recovery – PPA \\nBudget Comparison and Adjustments \\nComparison of Budget Authority and Request \\n(Dollars in Thousands) \\n FY 2022 Enacted FY 2023 Enacted FY 2024 President's Budget FY 2023 to FY 2024 Total Changes \\n Pos. FTE Amount Pos. FTE Amount Pos. FTE Amount Pos. FTE Amount Response 855 759 $211,183 896 806 $222,496 917 837 $234,861 21 31 $12,365 Recovery 342 293 $55,186 346 243 $62,061 346 283 $57,427 - 40 ($4,634) Total 1,197 1,052 $266,369 1,242 1,049 $284,557 1,263 1,120 $292,288 21 71 $7,731 Subtotal Discretionary - Appropriation 1,197 1,052 $266,369 1,242 1,049 $284,557 1,263 1,120 $292,288 21 71 $7,731 \\nPPA Level I Description \\n \\nThe Office of Response and Recovery provides leadership to build, sustain, and improve the coordination and delivery of support to citizens and \\nState, local, tribal and territorial governments to save lives, reduce suffering, protect property and recover from all hazards. \\n \\nResponse leads and coordinates efforts to maintain the core Federal disaster response operational capabilities necessary to respond to and stabi lize the \\neffects of incidents, including all hazards planning, disaster emergency communications, response teams, logistics capabi lities and the disaster \\nworkforce. Recovery provides disaster survivors and communities recovering from disasters with disaster assistance grants, resources, and support\\n\",\n",
       "  'id': '',\n",
       "  'title': '',\n",
       "  'filepath': '',\n",
       "  'url': '',\n",
       "  'metadata': {'chunk_id': '56'}},\n",
       " {'content': \"Source 2:\\n. The business management office within the ORR Front Office also provides financial management and acquisitions support, human \\nresource management, facilities and assets manageme nt and IT systems management. The median grade in ORR Front Office is GS-13. FY 2023 to \\nFY 2024 increase supports an evidence-building capacity in line with the 2018 Foundations of Evidence-Based Policy Making Act. \\n Operations and Support Response – PPA II \\nFEMA – O&S - 96 Field Leadership Directorate: The Field Leadership Directorate (FLD) personnel ensure the operational readiness of FEMA’s field leaders through \\nbuilding, training, qualifying, and leading the workforce in response to and recovery from federal incidents. FLD maintains t he Incident Management \\nAssistance Team (IMAT) Program. These teams provide immediate command and coordination support prior to or immediately following an \\nincident. The Field Leadership Program oversees and manages the day -to-day operations of Field Leadership Cadre positions, incl uding Federal \\nCoordinating Officers (FCO), through recruiting, hiring, equipping, training, qualifying, and managing deployments. The media n grade in FLD is \\nGS-14. FY 2023 to FY 2024 increase includes funding to support Disaster Workforce Readiness. \\n \\nField Operations Directorate: The personnel under the Field Operations Directorate (FOD) provide oversight and management of FEMA’s diverse \\nincident workforce to ensure operational readiness to achieve timely, effective, and integrated field operations that su pport the whole community \\nacross all mission areas. The median grade in FOD is GS -14. FY 2023 to FY 2024 increase includes the transfer for DHS Volunteer Force, funding to \\nsupport the Disaster Workforce Readiness and a realignment of staff to the Field Lea dership Directorate. \\n \\n Operations and Support Response – PPA II \\nFEMA – O&S - 97 Response – PPA Level II \\nNon Pay Budget Exhibits \\nNon Pay Summary \\n(Dollars in Thousands)FY 2022 Enacted FY 2023 Enacted FY 2024 President's Budget FY 2023 to FY 2024 Change Response $93,439 $98,997 $97,536 ($1,461) Total $93,439 $98,997 $97,536 ($1,461) Subtotal Discretionary - Appropriation $93,439 $98,997 $97,536 ($1,461) Non Pay by Object Class \\n(Dollars in Thousands)FY 2022 Enacted FY 2023 Enacted FY 2024 President's Budget FY 2023 to FY 2024 Change 21.0 Travel and Transportation of Persons $5,199 $7,003 $7,003 - 22.0 Transportation of Things $28 $28 $28 - 23.3 Communications, Utilities, & Miscellaneous $1,511 $1,449 $1,449 - 24.0 Printing and Reproduction $13 $13 $13 - 25.1 Advisory & Assistance Services $403 $403 - ($403) 25.2 Other Services from Non -Federal Sources $36,928 $41,815 $42,257 $442 25.4 Operations & Maintenance of Facilities $845 $1,425 $1,425 - 25.7 Operation & Maintenance of Equipment $376 $376 $376 - 26.0 Supplies & Materials $2,609 $2,609 $2,609 - 31.0 Equipment $8,122 $6,471 $4,971 ($1,500) 41\\n\",\n",
       "  'id': '',\n",
       "  'title': '',\n",
       "  'filepath': '',\n",
       "  'url': '',\n",
       "  'metadata': {'chunk_id': '62'}},\n",
       " {'content': \"Source 3:\\n. FTE Amount Pos. FTE Amount Pos. FTE Amount Pos. FTE Amount Mission Support 1,329 1,181 $519,000 1,468 1,244 $586,196 1,543 1,362 $641,984 75 118 $55,788 Total 1,329 1,181 $519,000 1,468 1,244 $586,196 1,543 1,362 $641,984 75 118 $55,788 Subtotal Discretionary - Appropriation 1,329 1,181 $519,000 1,468 1,244 $586,196 1,543 1,362 $641,984 75 118 $55,788 \\nPPA Level I Description \\n \\nMission Support activities incorporate the essential command and control functions of the Agency, including information technology management \\nand cybersecurity, human capital management, acquisition management, security, real estate portfolio management and planning, records \\nmanagement, and occupational health and safety, as well as coordinate all policy, strategic planning, resources, managerial a nd administrative \\nservices. \\n Operations and Support Mission Support – PPA \\nFEMA – O&S - 49 Mission Support – PPA \\nBudget Authority and Obligations \\n(Dollars in Thousands)FY 2022 FY 2023 FY 2024 Enacted/Request $519,000 $586,196 $641,984 Carryover - Start of Year - - - Recoveries - - - Rescissions to Current Year/Budget Year - - - Net Sequestered Resources - - - Reprogramming/Transfers $2,742 - - Supplementals - - - Total Budget Authority $521,742 $586,196 $641,984 Collections - Reimbursable Resources $12,103 $12,103 $12,103 Collections - Other Sources - - - Total Budget Resources $533,845 $598,299 $654,087 Obligations (Actual/Estimates/Projections) $533,686 $598,299 $654,087 Personnel: Positions and FTE \\nEnacted/Request Positions 1,329 1,468 1,543 Enacted/Request FTE 1,181 1,244 1,362 Onboard and Actual FTE \\nOnboard (Actual/Estimates/Projections) 1,091 1,468 1,543 FTE (Actual/Estimates/Projections) 1,082 1,244 1,362 Operations and Support Mission Support – PPA \\nFEMA – O&S - 50 Mission Support – PPA \\nCollections – Reimbursable Resources \\n(Dollars in Thousands) \\n FY 2022 Enacted FY 2023 Enacted FY 2024 President's Budget \\n Pos. FTE Amount Pos. FTE Amount Pos. FTE Amount Department of Defense - Army 15 15 - 15 15 - 13 13 - Department of Homeland Security - U.S\\n\",\n",
       "  'id': '',\n",
       "  'title': '',\n",
       "  'filepath': '',\n",
       "  'url': '',\n",
       "  'metadata': {'chunk_id': '35'}},\n",
       " {'content': 'Source 4:\\n.. ................................ ................................ ................................ ........................... 39 \\nMission Support Assets and Infrastructure – PPA ................................ ................................ ................................ ................................ ............... 40 \\nBudget Comparison and Adjustments ................................ ................................ ................................ ................................ ...................... 40 \\nNon Pay Budget Exhi bits ................................ ................................ ................................ ................................ ................................ .......... 44 \\nCapital Investment Exhibits ................................ ................................ ................................ ................................ ................................ ...... 45 Federal Emergency Management Agency Procurement, Construction, and Improvements \\nFEMA – PC&I - 3 Grants Management Moderni zation – Investment ................................ ................................ ................................ ................................ .... 46 \\nFinancial Systems Modernization – Investment .............................\\n',\n",
       "  'id': '',\n",
       "  'title': '',\n",
       "  'filepath': '',\n",
       "  'url': '',\n",
       "  'metadata': {'chunk_id': '4'}},\n",
       " {'content': 'Source 5:\\n.......... ................................ ................................ ................................ .................... 8 \\nOperational Communications/Information Techno logy – PPA ................................ ................................ ................................ .............................. 9 \\nBudget Comparison and Adjustments ................................ ................................ ................................ ................................ ........................ 9 \\nNon Pay Budget Exhibits ................................ ................................ ................................ ................................ ................................ .......... 13 \\nCapital Investment Exhibits ................................ ................................ ................................ ................................ ................................ ...... 14 \\nIntegrated Public Alert and Warning System (IPAWS) – Investment ................................ ................................ ................................ ..... 15 \\nNational Continuity Program Strategic Partner Program – Investment ................................ ................................ .................\\n',\n",
       "  'id': '',\n",
       "  'title': '',\n",
       "  'filepath': '',\n",
       "  'url': '',\n",
       "  'metadata': {'chunk_id': '1'}}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "citations_json = [\n",
    "    {\n",
    "        \"content\": ct.node.text,\n",
    "        \"id\": \"\",\n",
    "        \"title\": \"\",\n",
    "        \"filepath\": \"\",\n",
    "        \"url\": \"\",\n",
    "        \"metadata\": ct.node.metadata\n",
    "    } for ct in qe_response.source_nodes\n",
    "]\n",
    "\n",
    "citations_json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2: \n",
    "### Try to get text splitting / metadata extraction pipeline to work using LlamaIndex Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to process=2 out of total directory size=2\n",
      "Single process to chunk and parse the files. --njobs > 1 can help performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingletonFormRecognizerClient: Creating instance of Form recognizer per process\n",
      "SingletonFormRecognizerClient: Skipping since credentials not provided. Assuming NO form recognizer extensions(like .pdf) in directory\n",
      "Processing PDF WITHOUT Document Intelligence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:41<00:41, 41.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF WITHOUT Document Intelligence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:00<00:00, 30.14s/it]\n"
     ]
    }
   ],
   "source": [
    "from data_utils import chunk_directory\n",
    "\n",
    "directory_path = settings.PREP_CONFIG[\"data_path\"]\n",
    "\n",
    "chunking_result = chunk_directory(\n",
    "        directory_path=directory_path,\n",
    "        ignore_errors=False,\n",
    "        num_tokens=settings.PREP_CONFIG[\"chunk_size\"],\n",
    "        min_chunk_size=10,\n",
    "        url_prefix = None,\n",
    "        token_overlap=settings.PREP_CONFIG[\"token_overlap\"],\n",
    "        form_recognizer_client = None,\n",
    "        use_layout = False,\n",
    "        njobs=1,\n",
    "        add_embeddings = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunking_result.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index import Document\n",
    "test = Document(text=\"hello\", metadata={\"title\": \"hello\"})\n",
    "test.metadata[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fema",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
